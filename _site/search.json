[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Visual Analytics and Applications",
    "section": "",
    "text": "Welcome to ISSS608 Visual Analytics and Application homepage:)\nIn this website, you will find my coursework prepared for this course."
  },
  {
    "objectID": "index.html#recent-posts",
    "href": "index.html#recent-posts",
    "title": "Visual Analytics and Applications",
    "section": "Recent Posts",
    "text": "Recent Posts"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Take-home_Ex03",
    "section": "",
    "text": "The objective of this project is to analyze and visualize the daily temperature records of December from the years 1983, 1993, 2003, 2013, and 2023. By leveraging analytics techniques, the project aims to gain insights into temperature trends over the past four decades and identify any patterns or anomalies. The ultimate goal is to create data-driven interactive visualizations that effectively communicate these insights.\nAnalyzing long-term temperature trends helps in understanding climate patterns and detecting any changes or anomalies that may have occurred over time.By examining temperature records, it becomes possible to assess the impact of climate change on local or regional climates, as well as its potential implications for ecosystems, agriculture, and human activities."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#load-packages",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#load-packages",
    "title": "Take-home_Ex03",
    "section": "2.1 Load Packages",
    "text": "2.1 Load Packages\nThe following code chunk loads the packages we need in this take home exercise.\n\npacman::p_load(ggstatsplot, tidyverse,plotly,dplyr,ggiraph,\n               patchwork, DT)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-preparation-overview",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-preparation-overview",
    "title": "Take-home_Ex03",
    "section": "2.2 Data preparation overview",
    "text": "2.2 Data preparation overview"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#import-data",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#import-data",
    "title": "Take-home_Ex03",
    "section": "2.3 Import Data",
    "text": "2.3 Import Data\nFor this take-home exercise, the data is sourced from the Meteorological Service Singapore, specifically from the Changi weather station, for the month of December. Data for the years 1983, 1993, 2003, 2013, and 2023 have been downloaded.\n\n\nShow the code\nchangi_1983 &lt;- read_csv(\"data/DAILYDATA_S24_198312.csv\",locale=locale(encoding=\"latin1\"))\nchangi_1993 &lt;- read_csv(\"data/DAILYDATA_S24_199312.csv\",locale=locale(encoding=\"latin1\"))\nchangi_2003 &lt;- read_csv(\"data/DAILYDATA_S24_200312.csv\",locale=locale(encoding=\"latin1\"))\nchangi_2013 &lt;- read_csv(\"data/DAILYDATA_S24_201312.csv\",locale=locale(encoding=\"latin1\"))\n\n\nchangi_1983 &lt;- changi_1983[, c(1, 2, 3, 4, 5, 9, 10, 11, 12, 13)]\ncolnames(changi_1983) &lt;- c(\"Station\", \"Year\", \"Month\", \"Day\", \"Daily_rainfall_total\",\"Mean_temperature\", \"Max_temperature\", \"Min_temperature\", \"Mean_wind_speed\", \"Max_wind_speed\")\n\nchangi_1993 &lt;- changi_1993[, c(1, 2, 3, 4, 5, 9, 10, 11, 12, 13)]\ncolnames(changi_1993) &lt;- c(\"Station\", \"Year\", \"Month\", \"Day\", \"Daily_rainfall_total\",\"Mean_temperature\", \"Max_temperature\", \"Min_temperature\", \"Mean_wind_speed\", \"Max_wind_speed\")\n\nchangi_2003 &lt;- changi_2003[, c(1, 2, 3, 4, 5, 9, 10, 11, 12, 13)]\ncolnames(changi_2003) &lt;- c(\"Station\", \"Year\", \"Month\", \"Day\", \"Daily_rainfall_total\",\"Mean_temperature\", \"Max_temperature\", \"Min_temperature\", \"Mean_wind_speed\", \"Max_wind_speed\")\n\nchangi_2013 &lt;- changi_2013[, c(1, 2, 3, 4, 5, 9, 10, 11, 12, 13)]\ncolnames(changi_2013) &lt;- c(\"Station\", \"Year\", \"Month\", \"Day\", \"Daily_rainfall_total\",\"Mean_temperature\", \"Max_temperature\", \"Min_temperature\", \"Mean_wind_speed\", \"Max_wind_speed\")\n\nchangi_2023 &lt;- read_csv(\"data/DAILYDATA_S24_202312.csv\")\n\nchangi_2023 &lt;- changi_2023[, c(1, 2, 3, 4, 5, 9, 10, 11, 12, 13)]\ncolnames(changi_2023) &lt;- c(\"Station\", \"Year\", \"Month\", \"Day\", \"Daily_rainfall_total\",\"Mean_temperature\", \"Max_temperature\", \"Min_temperature\", \"Mean_wind_speed\", \"Max_wind_speed\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#combine-data",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#combine-data",
    "title": "Take-home_Ex03",
    "section": "2.4 Combine data",
    "text": "2.4 Combine data\nThe following code chunk combined the processed dataframes together.\n\n\nShow the code\nlibrary(dplyr)\n\n# Combine the data frames\ncombined_df &lt;- bind_rows(changi_1983, changi_1993, changi_2003, changi_2013, changi_2023)\ncombined_df$Year &lt;- factor(combined_df$Year)\ncombined_df$Day &lt;- factor(combined_df$Day)\n\ndatatable(head(combined_df,n=5))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#check-missing-value",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#check-missing-value",
    "title": "Take-home_Ex03",
    "section": "2.5 Check missing value",
    "text": "2.5 Check missing value\nThe combined_df is a small dataframe. the following code can be used to check whether there is missing data.\n\n\nShow the code\n# Check for missing values in combined_df\nmissing_data &lt;- colSums(is.na(combined_df))\n\n# Print the number of missing values in each column\ndatatable(data.frame(missing_data))\n\n\n\n\n\n\n\nAfter comfirming there is no missing data, combined_df can be used for further analysis."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#mean-temperature-analysis",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#mean-temperature-analysis",
    "title": "Take-home_Ex03",
    "section": "3.1 Mean Temperature Analysis",
    "text": "3.1 Mean Temperature Analysis\nIn this column range chart, each column represents a day in December for each Year, and the height of the column represents the range between the minimum and maximum temperatures for that day. The color of the column is determined by the mean temperature for that day.\n\n\nShow the code\nlibrary(highcharter)\n# Create a new column for the combined date-like string\ncombined_df$Date &lt;- paste0(combined_df$Year, \"-December-\", combined_df$Day)\n\n# Create the tooltip\ntltip &lt;- tooltip_table(\n  c(\"Year\", \"Day\", \"Min\", \"Mean\", \"Max\"),\n  c(\"{point.Year}\", \"{point.Day}\", \"{point.Min_temperature}°\", \"{point.Mean_temperature}°\", \"{point.Max_temperature}°\")\n)\n\n# Create the highchart\nhchart(\n  combined_df,\n  type = \"columnrange\",\n  hcaes(\n    x = Date, \n    low = Min_temperature, \n    high = Max_temperature,\n    color = Mean_temperature\n  )\n) |&gt;\nhc_chart(\n  polar = TRUE\n) |&gt;\nhc_yAxis(\n  max = max(combined_df$Max_temperature) + 5,  # Adjust max and min values as needed\n  min = min(combined_df$Min_temperature) - 5,\n  labels = list(format = \"{value} C\"),\n  showFirstLabel = FALSE\n) |&gt;\nhc_xAxis(\n  title = list(text = \"\"), \n  gridLineWidth = 0.5,\n  labels = list(format = \"{value}\")\n) |&gt;\nhc_tooltip(\n  useHTML = TRUE,\n  pointFormat = tltip,\n  headerFormat = as.character(tags$small(\"{point.Date}\"))\n) |&gt; \nhc_title(\n  text = \"Climatical characteristics\"\n) |&gt; \nhc_size(\n  height = 600\n)\n\n\n\n\n\n\n\n\nThe chart shows variability in temperature patterns across the different years in December. Year-to-year comparisons reveal differences in mean and range of temperatures, there is a trends of increase in mean temperature over time.\nYear 1983:\n\nMore purple color indicates lower mean temperatures compared to other years.\nThe distribution of colors and heights of bars suggest a generally cooler December compared to the other years.\n\nYears 1993, 2003 and 2013:\n\nSimilar distribution of colors and heights of bars suggest similar temperature patterns in these years.\nThe colors and heights suggest a moderate temperature range for December.\n\nYear 2023:\n\nMore yellow color indicates higher mean temperatures compared to other years.\nTaller bars suggest higher temperature ranges, indicating a relatively warmer December compared to other years.\n\n\nWe can further confirm the temperature change using a heat map.\n\n\nShow the code\n# Assuming combined_df is your combined data frame containing Year, Day, and Mean_temperature columns\n\n# Create the heatmap using highcharter\ncolors &lt;- c(\"#FFFFFF\", \"#FFA500\", \"purple\")  # white to orange to red\n\n# Create the heatmap using highcharter with customized colors\nhchart(combined_df, \"heatmap\", hcaes(x = Year, y = Day, value = Mean_temperature)) %&gt;%\n  hc_colorAxis(stops = color_stops(n = length(colors), colors = colors))\n\n\n\n\n\n\n\nMoreover, we can utilize a line chart to more effectively visualize the trend of the mean temperature.\n\n\nShow the code\nhchart(combined_df, \"line\", hcaes(x = Day, y = Mean_temperature, group = Year))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#validating-daily-temperature-increase",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#validating-daily-temperature-increase",
    "title": "Take-home_Ex03",
    "section": "3.2 Validating Daily Temperature Increase",
    "text": "3.2 Validating Daily Temperature Increase\nIn order to validate the value of daily mean temperature increase, we need a new data frame to store the calculated daily mean temperature.\n\n\nShow the code\navg_temp &lt;- aggregate(Mean_temperature ~ Year, data = combined_df, FUN = function(x) round(mean(x), 2))\n\n# Rename the Mean_temperature column to Avg_Temp\nnames(avg_temp)[2] &lt;- \"Avg_Temp\"\n\n# Print the new dataframe\ndatatable(avg_temp)\n\n\n\n\n\n\n\n\n\nShow the code\nhchart(avg_temp, \"line\", hcaes(x = Year, y = Avg_Temp)) %&gt;%\n  hc_title(text = \"Daily Average Temperature by Year\") %&gt;%\n  hc_yAxis(title = list(text = \"Temperature\")) %&gt;%\n  hc_xAxis(title = list(text = \"Year\"))\n\n\n\n\n\n\n\n\nFrom the data table and interactive line chart above, we can calculate that the increase in daily mean temperature from 1983 to 2023 is 1.89 which is within the range given(Daily mean temperature are projected to increase by 1.4 to 4.6)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#max-and-min-temperature-analysis",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#max-and-min-temperature-analysis",
    "title": "Take-home_Ex03",
    "section": "3.3 Max and Min Temperature Analysis",
    "text": "3.3 Max and Min Temperature Analysis\n\n\nShow the code\np &lt;- ggplot(data = combined_df, aes(x = as.factor(Year), y = Mean_temperature)) +\n  geom_boxplot(aes(y = Max_temperature, fill = \"Max Temperature\"), alpha = 0.7) +\n  geom_boxplot(aes(y = Min_temperature, fill = \"Min Temperature\"), alpha = 0.7) +\n  labs(title = \"Temperature Distribution by Year\",\n       x = \"Year\",\n       y = \"Temperature\",\n       fill = \"Variable\") +\n  scale_fill_manual(values = c( \"Max Temperature\" = \"indianred\", \"Min Temperature\" = \"lightskyblue2\")) +\n  theme_minimal()\n\n# Make the plot interactive\np &lt;- ggplotly(p, tooltip = c(\"Year\", \"Max_temperature\",  \"Min_temperature\"))\n\n# Print the plot\nprint(p)\n\n\n\nFrom the interactive box plot shown above, we can note a general increasing trend in minimum temperatures. The increases in 1993 and 2023 compared to the previous decade are particularly noteworthy. Additionally, regarding the spread of the box plot, 2013 exhibits the widest temperature range, while 2023 has the smallest."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#temperature-and-wind-speed-analysis",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#temperature-and-wind-speed-analysis",
    "title": "Take-home_Ex03",
    "section": "3.4 Temperature and Wind Speed Analysis",
    "text": "3.4 Temperature and Wind Speed Analysis\nGiven that wind speed is included in the dataset, it would be intriguing to investigate the possible relationship between mean temperature and mean wind speed. To begin, we can employ a simple scatter plot with a trendline to visualize the distribution of mean temperature and mean wind speed.\n\n\nShow the code\n# Scatter plot with trend line\nggplot(combined_df, aes(x = Mean_temperature, y = Mean_wind_speed)) +\n  geom_point() +  # Add points for scatter plot\n  geom_smooth(method = \"lm\", se = FALSE) +  # Add linear trend line\n  labs(x = \"Mean Temperature\", y = \"Mean Wind Speed\", title = \"Relationship between Mean Wind Speed and Mean Temperature\")\n\n\n\n\n\nBased on the plot above, we can see a positive correlation between mean temperature and mean wind speed. However, the scattered distribution of the points suggests that the correlation is not particularly strong.\n\n\nShow the code\nplot_ly(data = combined_df, \n        x = ~Mean_temperature, \n        y = ~Mean_wind_speed, \n        color = ~Year)\n\n\n\n\n\n\nBy creating an interactive scatter plot of mean temperature and mean wind speed, with the points colored by year, we can observe that in 2023, both mean temperature and mean wind speed are higher(upper right corner) compared to other years, while in 1983, they are the lowest(lower left corner).\nTo visualize the change over these 50 years more effectively, we can use an animation to demonstrate the process.\n\n\nShow the code\nlibrary(ggplot2)\nlibrary(gganimate)\nlibrary(dplyr)\n\n# Create animated bubble plot\nggplot(combined_df, aes(x = Mean_wind_speed, y = Mean_temperature, size = Max_temperature, color =Max_temperature )) +\n  geom_point(alpha = 0.7) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {closest_state}', x = 'Mean_wind_speed', y = 'Mean_temperature') +\n  transition_states(Year) +\n  ease_aes('linear')"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-home_Ex01",
    "section": "",
    "text": "Andreas Schleicher, the director of education at the OECD, highlighted in a BBC article in 2016 that Singapore successfully attained academic excellence without significant disparities between children from affluent and underprivileged families. Additionally, various Ministers for Education in Singapore initiated a “every school a good school” campaign. Nevertheless, there is a prevalent public perception that disparities persist, particularly between elite and neighborhood schools, as well as among students from families with varying socioeconomic statuses, including those with higher and lower socioeconomic status, and between immigrant and non-immigrant families.\nThe 2022 Programme for International Student Assessment (PISA) data was released on December 5, 2022. PISA global education survey every three years to assess the education systems worldwide through testing 15 year old students in the subjects of mathematics, reading, and science.\n\n\n\nUse appropriate Exploratory Data Analysis (EDA) methods and ggplot2 functions to reveal:\n\nthe distribution of Singapore students’ performance in mathematics, reading, and science, and\nthe relationship between these performances with schools, gender and socioeconomic status of the students."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#setting-the-scene",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#setting-the-scene",
    "title": "Take-home_Ex01",
    "section": "",
    "text": "Andreas Schleicher, the director of education at the OECD, highlighted in a BBC article in 2016 that Singapore successfully attained academic excellence without significant disparities between children from affluent and underprivileged families. Additionally, various Ministers for Education in Singapore initiated a “every school a good school” campaign. Nevertheless, there is a prevalent public perception that disparities persist, particularly between elite and neighborhood schools, as well as among students from families with varying socioeconomic statuses, including those with higher and lower socioeconomic status, and between immigrant and non-immigrant families.\nThe 2022 Programme for International Student Assessment (PISA) data was released on December 5, 2022. PISA global education survey every three years to assess the education systems worldwide through testing 15 year old students in the subjects of mathematics, reading, and science."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#task",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#task",
    "title": "Take-home_Ex01",
    "section": "",
    "text": "Use appropriate Exploratory Data Analysis (EDA) methods and ggplot2 functions to reveal:\n\nthe distribution of Singapore students’ performance in mathematics, reading, and science, and\nthe relationship between these performances with schools, gender and socioeconomic status of the students."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#load-the-relevant-packages",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#load-the-relevant-packages",
    "title": "Take-home_Ex01",
    "section": "2.1 Load the relevant packages",
    "text": "2.1 Load the relevant packages\nWe use the pacman::p_load() function to load the required R packages into our working environment. The loaded packages are:\n\n\nShow the code\npacman::p_load(ggrepel, ggplot2,\n               distributional,\n               ggthemes, \n               tidyverse,\n              DT,dplyr,nortest) \n\n\npackage 'DT' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\carol\\AppData\\Local\\Temp\\RtmpEJbGhc\\downloaded_packages\n\n\n\n\n\n\n\n\n\nPackage\nDescription\n\n\n\n\nggrepel\nA package that enhances the ggplot2 plotting system. It provides functions to automatically adjust and repel overlapping text labels in ggplot2 plots\n\n\ndistributional\nA package designed for exploratory data analysis and visualization of univariate and bivariate distributions\n\n\nggthemes\nAn extension of ggplot2 that provides additional themes and color scales for creating visually appealing and consistent plots\n\n\ntidyverse\nA collection of R packages, including ggplot2, dplyr, tidyr, readr, purrr, and others.\n\n\nDT\nAn R package for creating interactive and dynamic tables and data tables\n\n\nnortest\nA package that includes various statistical tests and measures for assessing normality and symmetry of data"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#pre-processing-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#pre-processing-data",
    "title": "Take-home_Ex01",
    "section": "2.2 Pre-processing Data",
    "text": "2.2 Pre-processing Data\n\n2.2.1 Prepare main data-frame stu_df\nIn order to tidy up the data file:\n\nLoad stu_qqq_SG.rds data file.\nSelect specific columns representing student information, including identifiers, gender, school ID, parental education, training information, possession of various items, and academic scores in mathematics, reading, and science.\n\nStudent_ID: Student identifiers.\nGender: Gender information.\nSchool_ID: School identifiers.\nEducation_mother: Education level of the mother.\nEducation_father: Education level of the father.\nTraining_mother and Training_father: (These columns are currently commented out, so not included in the final data frame.)\nPossession_room, Possession_computer, Possession_software, Possession_phone, Possession_internet, and Possession_book: Information about possession of various items.\nMath_Average, Reading_Average, Science_Average: Average scores in mathematics, reading, and science, respectively.\nAverage_score: Overall average score calculated as the mean of math, reading, and science scores.\n\ncalculated average scores for mathematics, reading, and science separately using the rowMeans function.\ncreated a new data frame stu_df by combining the selected columns and calculated average scores.\n\n\n\nShow the code\nstu_qqq_SG &lt;- \n  read_rds(\"data/stu_qqq_SG.rds\")\n\nstudent_columns &lt;- \"CNTSTUID\"\ngender_columns &lt;- \"ST004D01T\"\nschool_columns &lt;- \"CNTSCHID\"\n\neducation_column_mother &lt;- \"ST005Q01JA\"\neducation_column_father &lt;- \"ST007Q01JA\"\n\ntraining_column_mother &lt;- \"ST006Q01JA\"\ntraining_column_father &lt;- \"ST008Q01JA\"\npossession_room_column &lt;- \"ST250Q01JA\"\npossession_computer_column &lt;- \"ST250Q02JA\"\npossession_software_column &lt;- \"ST250Q03JA\"\npossession_phone_column &lt;- \"ST250Q04JA\"\npossession_internet_column &lt;- \"ST250Q05JA\"\npossession_book_column &lt;- \"ST255Q01JA\"\n\n\n\nmath_columns &lt;- c(\"PV1MATH\", \"PV2MATH\", \"PV3MATH\", \"PV4MATH\", \"PV5MATH\", \"PV6MATH\", \"PV7MATH\", \"PV8MATH\", \"PV9MATH\", \"PV10MATH\")\nreading_columns &lt;- c(\"PV1READ\", \"PV2READ\", \"PV3READ\", \"PV4READ\", \"PV5READ\", \"PV6READ\", \"PV7READ\", \"PV8READ\", \"PV9READ\", \"PV10READ\")\nscience_columns &lt;- c(\"PV1SCIE\", \"PV2SCIE\", \"PV3SCIE\", \"PV4SCIE\", \"PV5SCIE\", \"PV6SCIE\", \"PV7SCIE\", \"PV8SCIE\", \"PV9SCIE\", \"PV10SCIE\")\n\nstudent_ID &lt;- stu_qqq_SG[, student_columns, drop = FALSE]\ngender &lt;- stu_qqq_SG[, gender_columns, drop = FALSE]\nschool_ID &lt;- stu_qqq_SG[, school_columns, drop = FALSE]\neducation_mother &lt;- stu_qqq_SG[, education_column_mother, drop = FALSE]\neducation_father &lt;- stu_qqq_SG[, education_column_father, drop = FALSE]\n\ntraining_mother &lt;- stu_qqq_SG[, training_column_mother, drop = FALSE]\ntraining_father &lt;- stu_qqq_SG[, training_column_father, drop = FALSE]\npossession_room &lt;- stu_qqq_SG[, possession_room_column, drop = FALSE]\npossession_computer &lt;- stu_qqq_SG[, possession_computer_column, drop = FALSE]\npossession_software &lt;- stu_qqq_SG[, possession_software_column, drop = FALSE]\npossession_phone &lt;- stu_qqq_SG[, possession_phone_column, drop = FALSE]\npossession_internet &lt;- stu_qqq_SG[, possession_internet_column, drop = FALSE]\npossession_book &lt;- stu_qqq_SG[, possession_book_column, drop = FALSE]\n\nmath_avg &lt;- rowMeans(stu_qqq_SG[, math_columns, drop = FALSE])\nreading_avg &lt;- rowMeans(stu_qqq_SG[, reading_columns, drop = FALSE])\nscience_avg &lt;- rowMeans(stu_qqq_SG[, science_columns, drop = FALSE])\n\n\nstu_df &lt;- data.frame(Student_ID = student_ID,\n  Gender = gender,\n  School_ID = school_ID,\n  Education_mother = education_mother,\n  Education_father = education_father,\n \n#  Training_mother = training_mother,\n#  Training_father = training_father,\n  Possession_room = possession_room,\n  Possession_computer = possession_computer,\n  Possession_software = possession_software,\n  Possession_phone = possession_phone,\n  Possession_internet = possession_internet,\n  Possession_book = possession_book,\n  \n  Math_Average = round(math_avg,digits=2),\n  Reading_Average = round(reading_avg,digits=2),\n  Science_Average = round(science_avg,digits=2),\nAverage_score=round(((math_avg+reading_avg+science_avg)/3),digits=2))\n\n\nThis is the first 5 rows of processed data-frame stu_df :\n\n\nShow the code\nnames(stu_df) &lt;- c(\"Student_ID\",\"Gender\",\"School_ID\",\"Education_mother\",\n                   \"Education_father\",\"Possession_room\",\"Possession_computer\",\n                   \"Possession_software\",\"Possession_phone\",\n                   \"Possession_internet\",\"Possession_book\",\"Math_Average\",\n                   \"Reading_Average\",\"Science_Average\",\"Average_Score\")\n\ndatatable(head(stu_df, n=5), options = list(dom='t'), \n              caption = \"Data-frame 1: First 5 row of the student data\",\n              rownames = FALSE) \n\n\nError in datatable(head(stu_df, n = 5), options = list(dom = \"t\"), caption = \"Data-frame 1: First 5 row of the student data\", : could not find function \"datatable\"\n\n\n\n\n2.2.2 Prepare data-frame for performance by school analysis Score_by_School\nIn order to better visualize the relationship of performance by school, the following data-frame is being created. This code performs group-wise summary statistics on the stu_df dataset, grouping the data by the School_ID variable. The resulting summary, Score_by_School, includes mean scores for math, reading, science, and overall average scores.\nThis is the first 5 rows of processed data-frame Score_by_School :\n\n\nShow the code\n# Create Score_by_School dataframe\nScore_by_School &lt;- stu_df %&gt;%\n  group_by(School_ID) %&gt;%\n  summarize(\n    Math_Average = round(mean(Math_Average, na.rm = TRUE), digits = 2),\n    Reading_Average = round(mean(Reading_Average, na.rm = TRUE), digits = 2),\n    Science_Average = round(mean(Science_Average, na.rm = TRUE), digits = 2),\n    Average_score = round(mean(Average_Score, na.rm = TRUE), digits = 2)\n  )\n\n# Print the Score_by_School dataframe\ndatatable(head(Score_by_School, n=5), options = list(dom='t'), \n              caption = \"Table 2: First 5 row of School Average Scores\",\n              rownames = FALSE) \n\n\nError in datatable(head(Score_by_School, n = 5), options = list(dom = \"t\"), : could not find function \"datatable\""
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#performance-by-gender",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#performance-by-gender",
    "title": "Take-home_Ex01",
    "section": "4.1 Performance by Gender",
    "text": "4.1 Performance by Gender\nViolin plots can reveal the skewness of the data and the presence of outliers. Skewed or asymmetrical shapes in the violin plot may indicate differences in the spread or tail of the distribution between genders.\nThe central “box” or “kernel density” of the violin plot shows the central tendency and spread of the data for each gender group. It includes information about medians, quartiles, and interquartile ranges.\n\nMathReadingScienceAverage\n\n\n\n\nShow the code\nggplot(stu_df, aes(x = factor(Gender), y = Math_Average, fill = factor(Gender))) +\n geom_violin(trim = FALSE) +\n  geom_boxplot(width = 0.2, position = position_dodge(width = 0.75)) +\n  stat_summary(\n    fun = median,\n    geom = \"text\",\n    aes(label = round(after_stat(y), )),\n    position = position_dodge(width = 0.75),\n    vjust = -1,\n    size = 3,\n    color = \"black\"\n  ) +\n  stat_summary(\n    fun = mean,\n    geom = \"text\",\n    aes(label = round(after_stat(y), )),\n    position = position_dodge(width = 0.75),\n    vjust = 1.51,\n    size = 3,\n    color = \"#B00000\"\n  ) +\n   # Add geom_text layer for displaying mean dot in red\n  stat_summary(fun = mean, geom = \"point\", shape = 16, size = 3, color = \"#B00000\",\n               position = position_nudge(x = 0.0)) +\n  labs(title = \"Violin Plot with Box Plot and Labels for Math Score\",\n       subtitle = \"(Black text: Median score; Red dot & Red text: Mean score)\",\n       x = \"Gender\",\n       y = \"Math Score\") +\n  scale_fill_manual(values = c(\"1\" = \"pink3\", \"2\" = \"cadetblue3\"), name = \"Gender\", labels = c(\"1\" = \"Female\", \"2\" = \"Male\"))+\n  scale_x_discrete(labels = c(\"1\" = \"Female\", \"2\" = \"Male\"))+\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(stu_df, aes(x = factor(Gender), y = Reading_Average, fill = factor(Gender))) +\n geom_violin(trim = FALSE) +\n  geom_boxplot(width = 0.2, position = position_dodge(width = 0.75)) +\n  stat_summary(\n    fun = median,\n    geom = \"text\",\n    aes(label = round(after_stat(y), )),\n    position = position_dodge(width = 0.75),\n    vjust = -1,\n    size = 3,\n    color = \"black\"\n  ) +\n  stat_summary(\n    fun = mean,\n    geom = \"text\",\n    aes(label = round(after_stat(y), )),\n    position = position_dodge(width = 0.75),\n    vjust = 1.5,\n    size = 3,\n    color = \"#B00000\"\n  ) +\n   # Add geom_text layer for displaying mean dot in red\n  stat_summary(fun = mean, geom = \"point\", shape = 16, size = 3, color = \"#B00000\",\n               position = position_nudge(x = 0.0)) +\n  labs(title = \"Violin Plot with Box Plot and Labels for Reading Score\",\n       subtitle = \"(Black text: Median score; Red dot & Red text: Mean score)\",\n       x = \"Gender\",\n       y = \"Reading Score\") +\n  scale_fill_manual(values = c(\"1\" = \"pink3\", \"2\" = \"cadetblue3\"), name = \"Gender\", labels = c(\"1\" = \"Female\", \"2\" = \"Male\"))+\n  scale_x_discrete(labels = c(\"1\" = \"Female\", \"2\" = \"Male\"))+\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(stu_df, aes(x = factor(Gender), y = Science_Average, fill = factor(Gender))) +\n geom_violin(trim = FALSE) +\n  geom_boxplot(width = 0.2, position = position_dodge(width = 0.75)) +\n  stat_summary(\n    fun = median,\n    geom = \"text\",\n    aes(label = round(after_stat(y), )),\n    position = position_dodge(width = 0.75),\n    vjust = -1,\n    size = 3,\n    color = \"black\"\n  ) +\n  stat_summary(\n    fun = mean,\n    geom = \"text\",\n    aes(label = round(after_stat(y), )),\n    position = position_dodge(width = 0.75),\n    vjust = 1.5,\n    size = 3,\n    color = \"#B00000\"\n  ) +\n   # Add geom_text layer for displaying mean dot in red\n  stat_summary(fun = mean, geom = \"point\", shape = 16, size = 3, color = \"#B00000\",\n               position = position_nudge(x = 0.0)) +\n  labs(title = \"Violin Plot with Box Plot and Labels for Science Score\",\n       subtitle = \"(Black text: Median score; Red dot & Red text: Mean score)\",\n       x = \"Gender\",\n       y = \"Reading Score\") +\n  scale_fill_manual(values = c(\"1\" = \"pink3\", \"2\" = \"cadetblue3\"), name = \"Gender\", labels = c(\"1\" = \"Female\", \"2\" = \"Male\"))+\n  scale_x_discrete(labels = c(\"1\" = \"Female\", \"2\" = \"Male\"))+\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(stu_df, aes(x = factor(Gender), y = Average_Score, fill = factor(Gender))) +\n geom_violin(trim = FALSE) +\n  geom_boxplot(width = 0.2, position = position_dodge(width = 0.75)) +\n  stat_summary(\n    fun = median,\n    geom = \"text\",\n    aes(label = round(after_stat(y), )),\n    position = position_dodge(width = 0.75),\n    vjust = -1,\n    size = 3,\n    color = \"black\"\n  ) +\n  stat_summary(\n    fun = mean,\n    geom = \"text\",\n    aes(label = round(after_stat(y), )),\n    position = position_dodge(width = 0.75),\n    vjust = 1.5,\n    size = 3,\n    color = \"#B00000\"\n  ) +\n   # Add geom_text layer for displaying mean dot in red\n  stat_summary(fun = mean, geom = \"point\", shape = 16, size = 3, color = \"#B00000\",\n               position = position_nudge(x = 0.0)) +\n  labs(title = \"Violin Plot with Box Plot and Labels for Average Score\",\n       subtitle = \"(Black text: Median score; Red dot & Red text: Mean score)\",\n       x = \"Gender\",\n       y = \"Reading Score\") +\n  scale_fill_manual(values = c(\"1\" = \"pink3\", \"2\" = \"cadetblue3\"), name = \"Gender\", labels = c(\"1\" = \"Female\", \"2\" = \"Male\"))+\n  scale_x_discrete(labels = c(\"1\" = \"Female\", \"2\" = \"Male\"))+\n  theme_minimal()\n\n\n\n\n\n\n\n\nFrom the above violin plots, we can conclude:\n\nMale plot is more spread out, which indicates greater variability in scores within the male group\nFemale group has better performance in Reading while male group has better performance in math and science (interpret based on median and mean)\nFemale group and male group have similar average performance\nAlmost all the distribution are left skewed, indicating a concentration of students with relatively higher scores, but a few students have much lower scores"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#performance-by-school",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#performance-by-school",
    "title": "Take-home_Ex01",
    "section": "4.2 Performance by School",
    "text": "4.2 Performance by School\nBy using box-plot, we can visualize the performance of the schools. Box-plot allows to identify outliers so that we can identify the top 3 schools and bottom 2 schools.\n\n\nShow the code\nScore_long &lt;- Score_by_School %&gt;%\n  pivot_longer(\n    cols = c(\"Math_Average\", \"Reading_Average\", \"Science_Average\", \"Average_score\"),\n    names_to = \"Score_Type\",\n    values_to = \"Score\"\n  )\n\n# Calculate outliers using the IQR method\noutliers &lt;- Score_long %&gt;%\n  group_by(Score_Type) %&gt;%\n  summarize(\n    lower_limit = quantile(Score, 0.25) - 1.5 * IQR(Score),\n    upper_limit = quantile(Score, 0.75) + 1.5 * IQR(Score)\n  ) %&gt;%\n  left_join(Score_long, by = \"Score_Type\") %&gt;%\n  filter(Score &lt; lower_limit | Score &gt; upper_limit)\n\n# Identify the top 3 and bottom 2 schools for each Score_Type\nselected_schools &lt;- outliers %&gt;%\n  group_by(Score_Type) %&gt;%\n  arrange(desc(Score)) %&gt;%\n  slice_head(n = 3) %&gt;%\n  bind_rows(\n    outliers %&gt;%\n      group_by(Score_Type) %&gt;%\n      arrange(Score) %&gt;%\n      slice_head(n = 2)\n  )\n\n# Custom fill colors\ncustom_fill_colors &lt;- c(\"Math_Average\" = \"mistyrose3\", \n                        \"Reading_Average\" = \"paleturquoise3\", \n                        \"Science_Average\" = \"darkolivegreen3\",\n                        \"Average_score\" = \"lavender\")\n\n# Plot box plot with selected outlier labels\nggplot(Score_long, aes(x = Score_Type, y = Score, fill = Score_Type)) +\n  geom_boxplot(fill = custom_fill_colors) +  # Use custom fill colors\n  geom_text_repel(data = selected_schools, aes(label = School_ID), \n                  box.padding = 0.8, point.padding = 0.5, max.iter = 500, size = 3) +\n  labs(title = \"Distribution of Scores by School\",\n       x = \"Subject\",\n       y = \"Score\",\n       fill = \"Score Type\") +\n  scale_fill_manual(values = custom_fill_colors) +  # Set fill colors manually\n  theme_minimal()\n\n\n\n\n\nFrom the above box-plot:\n\nSchool ID 70200001, 70200003, 70200101 are considered the top performing schools\nFor all three subject, school ID 70200115 and 70200149 are the 2 schools with worst performance"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#performance-by-socioeconomic-factors",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#performance-by-socioeconomic-factors",
    "title": "Take-home_Ex01",
    "section": "4.3 Performance by Socioeconomic factors",
    "text": "4.3 Performance by Socioeconomic factors\n\n4.3.1 Performance distribution by highest level of schooling of Parents\nDensity plot allows for the exploration of the distribution of performance across different levels of schooling of the parents. The inclusion of red mean lines enhances the understanding of central tendencies in each category.\n\n\n\nHighest level of schooling\nDescription\n\n\n\n\n1\n&lt;ISCED level 3.4&gt;\n\n\n2\n&lt;ISCED level 3.3&gt;\n\n\n3\n&lt;ISCED level 2&gt;\n\n\n4\n&lt;ISCED level 1&gt;\n\n\n5\nDid not complete &lt;ISCED level 1&gt;\n\n\n\n\n4.3.1.1 Highest level of schooling of mother\n\nMathReadingScienceAverage\n\n\n\n\nShow the code\nmean_data &lt;- stu_df %&gt;%\n  filter(!is.na(Education_mother)) %&gt;%\n  group_by(Education_mother) %&gt;%\n  summarize(mean_value = mean(Math_Average, na.rm = TRUE))\n\nggplot(na.omit(stu_df), aes(x = Math_Average, fill = Education_mother)) +\n  geom_density(alpha = 0.5) +\n  geom_vline(data = mean_data, aes(xintercept = mean_value),\n             color = \"red\", linetype = \"dashed\") +\n  facet_wrap(~Education_mother, scales = \"free_y\", ncol = 1) +\n  labs(title = \"Density plot of math average score by highest level of schooling of mother\",\n       subtitle = \"Red line represents the mean\",\n       x = \"Math Average Score\",\n       fill = \"level of schooling(mother)\") +\n    scale_fill_gradient(low = \"skyblue\", high = \"grey45\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nShow the code\nmean_data &lt;- stu_df %&gt;%\n  filter(!is.na(Education_mother)) %&gt;%\n  group_by(Education_mother) %&gt;%\n  summarize(mean_value = mean(Reading_Average, na.rm = TRUE))\n\nggplot(na.omit(stu_df), aes(x = Reading_Average, fill = Education_mother)) +\n  geom_density(alpha = 0.5) +\n  geom_vline(data = mean_data, aes(xintercept = mean_value),\n             color = \"red\", linetype = \"dashed\") +\n  facet_wrap(~Education_mother, scales = \"free_y\", ncol = 1) +\n  labs(title = \"Density plot of reading average score by highest level of schooling of mother\",\n       subtitle = \"Red line represents the mean\",\n       x = \"Reading Average Score\",\n       fill = \"level of schooling(mother)\") +\n    scale_fill_gradient(low = \"skyblue\", high = \"grey45\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nShow the code\nmean_data &lt;- stu_df %&gt;%\n  filter(!is.na(Education_mother)) %&gt;%\n  group_by(Education_mother) %&gt;%\n  summarize(mean_value = mean(Science_Average, na.rm = TRUE))\n\nggplot(na.omit(stu_df), aes(x = Science_Average, fill = Education_mother)) +\n  geom_density(alpha = 0.5) +\n  geom_vline(data = mean_data, aes(xintercept = mean_value),\n             color = \"red\", linetype = \"dashed\") +\n  facet_wrap(~Education_mother, scales = \"free_y\", ncol = 1) +\n  labs(title = \"Density plot of science average score by highest level of schooling of mother\",\n       subtitle = \"Red line represents the mean\",\n       x = \"Science Average Score\",\n       fill = \"level of schooling(mother)\") +\n    scale_fill_gradient(low = \"skyblue\", high = \"grey45\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nShow the code\nmean_data &lt;- stu_df %&gt;%\n  filter(!is.na(Education_mother)) %&gt;%\n  group_by(Education_mother) %&gt;%\n  summarize(mean_value = mean(Average_Score, na.rm = TRUE))\n\nggplot(na.omit(stu_df), aes(x = Average_Score, fill = Education_mother)) +\n  geom_density(alpha = 0.5) +\n  geom_vline(data = mean_data, aes(xintercept = mean_value),\n             color = \"red\", linetype = \"dashed\") +\n  facet_wrap(~Education_mother, scales = \"free_y\", ncol = 1) +\n  labs(title = \"Density plot of average score score by highest level of schooling of mother\",\n       subtitle = \"Red line represents the mean\",\n       x = \"Average Score\",\n       fill = \"level of schooling(mother)\") +\n  scale_fill_gradient(low = \"skyblue\", high = \"grey45\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n4.3.1.2 Highest level of schooling of father\n\nMathReadingScienceAverage\n\n\n\n\nShow the code\nmean_data &lt;- stu_df %&gt;%\n  filter(!is.na(Education_father)) %&gt;%\n  group_by(Education_father) %&gt;%\n  summarize(mean_value = mean(Math_Average, na.rm = TRUE))\n\nggplot(na.omit(stu_df), aes(x = Math_Average, fill = Education_father)) +\n  geom_density(alpha = 0.5) +\n  geom_vline(data = mean_data, aes(xintercept = mean_value),\n             color = \"red\", linetype = \"dashed\") +\n  facet_wrap(~Education_father, scales = \"free_y\", ncol = 1) +\n  labs(title = \"Density plot of math average score by highest level of schooling of father\",\n       subtitle = \"Red line represents the mean\",\n       x = \"Math Average Score\",\n       fill = \"level of schooling(father)\") +\n  scale_fill_gradient(low = \"darkolivegreen3\", high = \"grey45\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nShow the code\nmean_data &lt;- stu_df %&gt;%\n  filter(!is.na(Education_father)) %&gt;%\n  group_by(Education_father) %&gt;%\n  summarize(mean_value = mean(Reading_Average, na.rm = TRUE))\n\nggplot(na.omit(stu_df), aes(x = Reading_Average, fill = Education_father)) +\n  geom_density(alpha = 0.5) +\n  geom_vline(data = mean_data, aes(xintercept = mean_value),\n             color = \"red\", linetype = \"dashed\") +\n  facet_wrap(~Education_father, scales = \"free_y\", ncol = 1) +\n  labs(title = \"Density plot of reading average score by highest level of schooling of father\",\n       subtitle = \"Red line represents the mean\",\n       x = \"Reading Average Score\",\n       fill = \"level of schooling(father)\") +\n  scale_fill_gradient(low = \"darkolivegreen3\", high = \"grey45\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nShow the code\nmean_data &lt;- stu_df %&gt;%\n  filter(!is.na(Education_father)) %&gt;%\n  group_by(Education_father) %&gt;%\n  summarize(mean_value = mean(Science_Average, na.rm = TRUE))\n\nggplot(na.omit(stu_df), aes(x = Science_Average, fill = Education_father)) +\n  geom_density(alpha = 0.5) +\n  geom_vline(data = mean_data, aes(xintercept = mean_value),\n             color = \"red\", linetype = \"dashed\") +\n  facet_wrap(~Education_father, scales = \"free_y\", ncol = 1) +\n  labs(title = \"Density plot of science average score by highest level of schooling of father\",\n       subtitle = \"Red line represents the mean\",\n       x = \"Science Average Score\",\n       fill = \"level of schooling(father)\") +\n  scale_fill_gradient(low = \"darkolivegreen3\", high = \"grey45\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nShow the code\nmean_data &lt;- stu_df %&gt;%\n  filter(!is.na(Education_father)) %&gt;%\n  group_by(Education_father) %&gt;%\n  summarize(mean_value = mean(Average_Score, na.rm = TRUE))\n\nggplot(na.omit(stu_df), aes(x = Average_Score, fill = Education_father)) +\n  geom_density(alpha = 0.5) +\n  geom_vline(data = mean_data, aes(xintercept = mean_value),\n             color = \"red\", linetype = \"dashed\") +\n  facet_wrap(~Education_father, scales = \"free_y\", ncol = 1) +\n  labs(title = \"Density plot of average score score by highest level of schooling of father\",\n       subtitle = \"Red line represents the mean\",\n       x = \"Average Score\",\n       fill = \"level of schooling(father)\") +\n  scale_fill_gradient(low = \"darkolivegreen3\", high = \"grey45\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nFrom the density plot above, we can draw the following conclusion:\n\nHigher Schooling Level of Parents:\n\nAs the highest schooling level of parents increases, the density plot shows a tendency towards higher mean performance. This trend is particularly significant for parents who completed &lt;ISCED level 3.3&gt;.\nThis suggests a positive correlation between the educational attainment of parents and the academic performance of students. Students with parents who achieved higher education levels tend to have higher mean scores.\n\nNormal Distribution and Right Skewness:\n\nFor parents with lower schooling levels, the density plot tends to be normal distributed, and as the schooling level decreases further, it becomes right-skewed.\nThis indicates that as the educational background of parents becomes less advanced, the distribution of students’ performance becomes more spread out and right-skewed, with a concentration towards lower scores.\n\nSimilar Mean Performance for Father’s Education:\n\nInterestingly, for fathers who completed &lt;ISCED level 2&gt;, &lt;ISCED level 1&gt;, and did not complete &lt;ISCED level 1&gt;, the students’ mean performance is considered similar. This suggests that, at least in these specific educational levels, education level of father might not be a significant impact on in the academic performance of students for these 3 schooling levels.\n\nMore Significant Impact of Mothers’ Education:\n\nOn the mother’s side, there is a noticeable relationship between higher schooling levels and better student performance. As mothers’ education level increases, the density plot shows a corresponding increase in mean scores.\nThis may implies a stronger influence of mothers’ educational attainment on students’ academic performance compared to fathers.\n\n\nIn summary, the density plot provides insights into the complex relationship between students’ performance and the highest schooling level of parents. It highlights the impact of parental education, with a clear positive association between higher parental education and higher mean performance. The differences observed between mothers and fathers emphasize the varying roles and influences of each parent in shaping students’ academic outcomes.\n\n\n\n4.3.2 Performance distribution by number of book in students’ home\nThe presence of books in a home often reflects a positive educational environment. It can indicate a household that values literacy, learning, and intellectual curiosity.\nUsing density plot, we can visualize how performance is distributed for different student group having different number of books in home.\n\n\n\nNumber of book in students’ home\nDescription\n\n\n\n\n1\nThere are no books\n\n\n2\n1-10 books\n\n\n3\n11-25 books\n\n\n4\n26-100 books\n\n\n5\n101-200 books\n\n\n6\n201-500 books\n\n\n7\nMore than 500 books\n\n\n\n\nAverageReading\n\n\n\n\nShow the code\nmean_data &lt;- stu_df %&gt;%\n  filter(!is.na(Possession_book)) %&gt;%\n  group_by(Possession_book) %&gt;%\n  summarize(mean_value = mean(Average_Score, na.rm = TRUE))\n\nggplot(na.omit(stu_df), aes(x = Average_Score, fill = Possession_book)) +\n  geom_density(alpha = 0.5) +\n  geom_vline(data = mean_data, aes(xintercept = mean_value),\n             color = \"red\", linetype = \"dashed\") +\n  facet_wrap(~Possession_book, scales = \"free_y\", ncol = 1) +\n  labs(title = \"Density plot of average score score by number of books owned\",\n       subtitle = \"Red line represents the mean\",\n       x = \"Average Score\",\n       fill = \"number of books owned\") +\n  scale_fill_gradient(low = \"grey45\", high = \"thistle3\") +\n  theme_minimal()+\n  theme(axis.text.y = element_text(size = 5))+  \n  scale_y_continuous(breaks = seq(0, 0.0055, by = 0.0025))\n\n\n\n\n\n\n\n\n\nShow the code\nmean_data &lt;- stu_df %&gt;%\n  filter(!is.na(Possession_book)) %&gt;%\n  group_by(Possession_book) %&gt;%\n  summarize(mean_value = mean(Reading_Average, na.rm = TRUE))\n\nggplot(na.omit(stu_df), aes(x = Reading_Average, fill = Possession_book)) +\n  geom_density(alpha = 0.5) +\n  geom_vline(data = mean_data, aes(xintercept = mean_value),\n             color = \"red\", linetype = \"dashed\") +\n  facet_wrap(~Possession_book, scales = \"free_y\", ncol = 1) +\n  labs(title = \"Density plot of average reading score score by number of books owned\",\n       subtitle = \"Red line represents the mean\",\n       x = \"Reading average Score\",\n       fill = \"number of books owned\") +\n  scale_fill_gradient(low = \"grey45\", high = \"thistle3\") +\n  theme_minimal()+\n  theme(axis.text.y = element_text(size = 5))+  \n  scale_y_continuous(breaks = seq(0, 0.0055, by = 0.0025))\n\n\n\n\n\n\n\n\nFrom the density plot, we can interpret that:\n\nFor students with no books in their homes, the density plot is right-skewed. This suggests that a lack of books is associated with a concentration of lower academic scores. The right skewness indicates that the majority of students in this group may have below-average scores.\nAs the number of books in the home increases, the density plot becomes more left-skewed. This trend suggests a positive correlation between the abundance of books and higher academic performance. The left skewness indicates a concentration of higher scores, with more students performing above the average.\nThe observation that the mean score of students increases as the number of books in the home increases aligns with the general trend of a left-skewed density plot. This indicates that, on average, students with access to a greater number of books tend to achieve higher academic scores.\nA notable deviation from the general trend occurs for students whose homes have “more than 500 books.” In this category, the mean score decreases, contrary to the overall positive relationship observed. This suggests that there may be diminishing returns in terms of academic performance when the number of books surpasses a certain threshold.\n\nIn summary, the density plot illustrates a positive association between the number of books in the home and student performance. However, the deviation observed for the “more than 500 books” category suggests a nuanced relationship, highlighting the need to consider optimal conditions for leveraging the positive influence of books on academic outcomes.\n\n\n4.3.3 Performance distribution by internet access\nAnalyzing student performance by whether the student has internet access provides a comprehensive perspective on the influence of digital resources and technologies on academic outcomes. It helps educators, policymakers, and researchers understand the role of internet access in shaping students’ learning experiences and achievements.\n\n\nShow the code\nggplot(na.omit(stu_df), aes(x = as.factor(Possession_internet), y = Average_Score, fill = factor(Possession_internet))) +\n  geom_violin(trim = FALSE) +\n  geom_boxplot(width = 0.2, position = position_dodge(width = 0.75)) +\n  stat_summary(\n    fun = median,\n    geom = \"text\",\n    aes(label = round(after_stat(y), )),\n    position = position_dodge(width = 0.75),\n    vjust = 2,\n    size = 3,\n    color = \"black\"\n  ) +\n  stat_summary(\n    fun = mean,\n    geom = \"text\",\n    aes(label = round(after_stat(y), )),\n    position = position_dodge(width = 0.75),\n    vjust = -1,\n    size = 3,\n    color = \"#B00000\"\n  ) +\n   # Add geom_text layer for displaying mean dot in red\n  stat_summary(fun = mean, geom = \"point\", shape = 16, size = 3, color = \"#B00000\",\n               position = position_nudge(x = 0.0)) +\n  labs(title = \"Average score Distribution by Internet Access\",\n       subtitle = \"Black text: Median score; Red dot & Red text:Mean score\",\n       x = \"Internet Access\",\n       y = \"Average Score\") +\n  scale_fill_manual(values = c(\"1\" = \"lightcyan2\", \"2\" = \"khaki\"), name = \"Internet Access\", labels = c(\"1\" = \"Yes\", \"2\" = \"No\"))+\n  scale_x_discrete(labels = c(\"No\", \"Yes\"))+\n  theme_minimal()\n\n\n\n\n\nFrom above, we can conclude:\n\nMean and Median Comparison:\n\nFor students with no internet access, the mean performance is higher (562) compared to students with internet access (490). However, the median for students with no internet access (572) is higher than the median for students with internet access (471).\n\nWider Score Range with Internet Access:\n\nStudents with internet access exhibit a wider score range compared to those without internet access. The spread of scores is more diverse for students with internet access, indicating greater variability in academic performance.\nThere is a small portion of students with internet access who achieve an average score of 800 or higher. This suggests that, despite the wider score range, there are exceptional cases of very high academic performance among students with internet access.\n\nSkewness of distribution\n\nThe distribution of scores for students with internet access is right-skewed.\nThe distribution of scores for students without internet access is left-skewed. This indicates that a majority of students in this group tend to have above-average scores, with a concentration towards higher performance.\n\n\nIn summary, the violin plot provides a nuanced view of the performance of students based on internet access. It highlights the impact of internet and digital devices on students performance. In this case, Access to internet leads to decrease in performance for students."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#reference",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#reference",
    "title": "Take-home_Ex01",
    "section": "6. Reference",
    "text": "6. Reference\nOne-way ANOVA\nggplot density plot\nbox-plot stat summary\nviolin plot with box plot"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "title": "In-class_Ex01",
    "section": "",
    "text": "In this hands-on exercise, two R packages will be used. They are:\ntidyverse, and haven\n\ntidyverse\nhaven\n\nThe code chunk used is as follows:\n\npacman::p_load(tidyverse, haven)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#loading-r-packages",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#loading-r-packages",
    "title": "In-class_Ex01",
    "section": "",
    "text": "In this hands-on exercise, two R packages will be used. They are:\ntidyverse, and haven\n\ntidyverse\nhaven\n\nThe code chunk used is as follows:\n\npacman::p_load(tidyverse, haven)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#importing-pisa-data",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#importing-pisa-data",
    "title": "In-class_Ex01",
    "section": "Importing PISA data",
    "text": "Importing PISA data\nThe code chunk below uses ‘read_sas’ ‘haven’\n\nstu_qqq &lt;- read_sas(\"data/cy08msp_stu_qqq.sas7bdat\")\n\n\nstu_qqq_SG &lt;- stu_qqq %&gt;%\nfilter(CNT ==\"SGP\")\n\n\nwrite_rds(stu_qqq_SG,\n          \"data/stu_qqq_SG.rds\")\n\n\nstu_qqq_SG &lt;- \n  read_rds(\"data/stu_qqq_SG.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "title": "Hands-on_Ex04",
    "section": "",
    "text": "ggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters\n\n\n\n\n\n\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\n\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\n\nShow the code\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\n###1.2.4 Oneway ANOVA Test: ggbetweenstats() methodIn the code chunk below,ggbetweenstats()` is used to build a visual for One-way ANOVA test on English score by race.\n\n\nShow the code\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\n\nShow the code\nexam1 &lt;- exam %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,90,100))\n)\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)\n\n\n\n\n\n\n\n\n\nIn this section, you will learn how to visualise model diagnostic and model parameters by using parameters package. Toyota Corolla case study will be used. The purpose of study is to build a model to discover factors affecting prices of used-cars by taking into consideration a set of explanatory variables.\n\n\n\n\nShow the code\npacman::p_load(readxl, performance, parameters, see)\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …\n\n\n##1.3.2 Multiple Regression Model using lm() The code chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\n\nShow the code\nmodel &lt;- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n##1.3.3 Model Diagnostic: checking for multicolinearity: In the code chunk, check_collinearity() of performance package.\n\n\nShow the code\ncheck_collinearity(model)\n\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\nShow the code\ncheck_c &lt;- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\n\n\n\nChecking the normality assumption is an important step when working with linear regression models. The normality assumption in the context of linear regression refers to the normal distribution of the residuals (the differences between observed and predicted values).\n\n\nShow the code\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\ncheck_n &lt;- check_normality(model1)\nplot(check_n)\n\n\n\n\n\n\n\n\nIn the code chunk, check_heteroscedasticity() of performance package.\n\n\nShow the code\ncheck_h &lt;- check_heteroscedasticity(model1)\nplot(check_h)\n\n\n\n\n\n\n\n\nWe can also perform the complete by using check_model()\n\ncheck_model(model1)\n\n\n\n\n\n\n\nIn the code below, ggcoefstats() of ggstatsplot package to visualise the parameters of a regression model.\n\nggcoefstats(model1, \n            output = \"plot\")\n\n\n\n\n\nCoefficients and Confidence Intervals:\n\nEach point in the plot represents a coefficient estimate from your regression model.\nThe horizontal position of the point indicates the estimated coefficient value.\nThe vertical line extending from the point represents the 95% confidence interval for that coefficient.\n\nColor Coding:\n\nPoints and confidence intervals may be color-coded to indicate statistical significance. For example, significant coefficients might be colored differently from non-significant ones.\nIt’s common to use different colors for statistically significant (p &lt; 0.05) and non-significant (p ≥ 0.05) coefficients.\n\nVertical Reference Line:\n\nA vertical reference line at the value of 0 on the x-axis indicates the null hypothesis (no effect). Coefficients to the right of this line are positive, and those to the left are negative."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#learning-outcome",
    "title": "Hands-on_Ex04",
    "section": "",
    "text": "ggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#getting-started",
    "title": "Hands-on_Ex04",
    "section": "",
    "text": "pacman::p_load(ggstatsplot, tidyverse)\n\n\n\n\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\n\nShow the code\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\n###1.2.4 Oneway ANOVA Test: ggbetweenstats() methodIn the code chunk below,ggbetweenstats()` is used to build a visual for One-way ANOVA test on English score by race.\n\n\nShow the code\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\n\nShow the code\nexam1 &lt;- exam %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,90,100))\n)\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-models",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-models",
    "title": "Hands-on_Ex04",
    "section": "",
    "text": "In this section, you will learn how to visualise model diagnostic and model parameters by using parameters package. Toyota Corolla case study will be used. The purpose of study is to build a model to discover factors affecting prices of used-cars by taking into consideration a set of explanatory variables.\n\n\n\n\nShow the code\npacman::p_load(readxl, performance, parameters, see)\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …\n\n\n##1.3.2 Multiple Regression Model using lm() The code chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\n\nShow the code\nmodel &lt;- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n##1.3.3 Model Diagnostic: checking for multicolinearity: In the code chunk, check_collinearity() of performance package.\n\n\nShow the code\ncheck_collinearity(model)\n\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\nShow the code\ncheck_c &lt;- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\n\n\n\nChecking the normality assumption is an important step when working with linear regression models. The normality assumption in the context of linear regression refers to the normal distribution of the residuals (the differences between observed and predicted values).\n\n\nShow the code\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\ncheck_n &lt;- check_normality(model1)\nplot(check_n)\n\n\n\n\n\n\n\n\nIn the code chunk, check_heteroscedasticity() of performance package.\n\n\nShow the code\ncheck_h &lt;- check_heteroscedasticity(model1)\nplot(check_h)\n\n\n\n\n\n\n\n\nWe can also perform the complete by using check_model()\n\ncheck_model(model1)\n\n\n\n\n\n\n\nIn the code below, ggcoefstats() of ggstatsplot package to visualise the parameters of a regression model.\n\nggcoefstats(model1, \n            output = \"plot\")\n\n\n\n\n\nCoefficients and Confidence Intervals:\n\nEach point in the plot represents a coefficient estimate from your regression model.\nThe horizontal position of the point indicates the estimated coefficient value.\nThe vertical line extending from the point represents the 95% confidence interval for that coefficient.\n\nColor Coding:\n\nPoints and confidence intervals may be color-coded to indicate statistical significance. For example, significant coefficients might be colored differently from non-significant ones.\nIt’s common to use different colors for statistically significant (p &lt; 0.05) and non-significant (p ≥ 0.05) coefficients.\n\nVertical Reference Line:\n\nA vertical reference line at the value of 0 on the x-axis indicates the null hypothesis (no effect). Coefficients to the right of this line are positive, and those to the left are negative."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#installing-and-loading-the-packages-and-importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#installing-and-loading-the-packages-and-importing-data",
    "title": "Hands-on_Ex04",
    "section": "2.1 Installing and loading the packages and importing data",
    "text": "2.1 Installing and loading the packages and importing data\nFor the purpose of this exercise, the following R packages will be used, they are:\n\ntidyverse, a family of R packages for data science process,\nplotly for creating interactive plot,\ngganimate for creating animation plot,\nDT for displaying interactive html table,\ncrosstalk for for implementing cross-widget interactions (currently, linked brushing and filtering), and\nggdist for visualising distribution and uncertainty.\n\n\n\nShow the code\ndevtools::install_github(\"wilkelab/ungeviz\")\n\n\nError in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]): namespace 'htmltools' 0.5.6 is already loaded, but &gt;= 0.5.7 is required\n\n\nShow the code\npacman::p_load(ungeviz, plotly, crosstalk,\n               DT, ggdist, ggridges,\n               colorspace, gganimate, tidyverse)\n\n\npackage 'plotly' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\carol\\AppData\\Local\\Temp\\Rtmp8UAGXw\\downloaded_packages\npackage 'DT' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\carol\\AppData\\Local\\Temp\\Rtmp8UAGXw\\downloaded_packages\n\n\nShow the code\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualizing-the-uncertainty-of-point-estimates-with-interactive-error-bars",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualizing-the-uncertainty-of-point-estimates-with-interactive-error-bars",
    "title": "Hands-on_Ex04",
    "section": "2.2 Visualizing the uncertainty of point estimates with interactive error bars",
    "text": "2.2 Visualizing the uncertainty of point estimates with interactive error bars\n\n\nShow the code\nmy_sum &lt;- exam %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %&gt;%\n  mutate(se=sd/sqrt(n-1))\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4,8),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(\n                     x=reorder(RACE, -mean),\n                     ymin=mean-2.58*se, \n                     ymax=mean+2.58*se), \n                     width=0.2, \n                     colour=\"black\", \n                     alpha=0.9, \n                     size=0.5) +\n                   geom_point(aes(\n                     x=RACE, \n                     y=mean, \n                     text = paste(\"Race:\", `RACE`, \n                                  \"&lt;br&gt;N:\", `n`,\n                                  \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI:[\", \n                                  round((mean-2.58*se), digits = 2), \",\",\n                                  round((mean+2.58*se), digits = 2),\"]\")),\n                     stat=\"identity\", \n                     color=\"red\", \n                     size = 1.5, \n                     alpha=1) + \n                   xlab(\"Race\") + \n                   ylab(\"Average Scores\") + \n                   theme_minimal() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust=1)) +\n                   ggtitle(\"99% Confidence interval of average /&lt;br&gt;maths scores by race\")), \n                tooltip = \"text\"), \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class=\"compact\", \n                     width=\"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns=c('mean', 'sd', 'se'),\n                     digits=2))\n\n\nError in ggplotly((ggplot(shared_df) + geom_errorbar(aes(x = reorder(RACE, : could not find function \"ggplotly\""
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualizing-the-uncertainty-of-point-estimates-ggdist-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualizing-the-uncertainty-of-point-estimates-ggdist-methods",
    "title": "Hands-on_Ex04",
    "section": "2.3 Visualizing the uncertainty of point estimates: ggdist methods",
    "text": "2.3 Visualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\n\nShow the code\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"pink3\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "title": "Hands-on_Ex04",
    "section": "2.4 Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)",
    "text": "2.4 Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)\nHypothetical Outcome Plots (HOPs) are a visualization technique used to depict uncertainty in statistical analyses, particularly in the context of causal inference and counterfactual scenarios. HOPs provide a way to explore the range of potential outcomes under different conditions, helping users understand the impact of uncertainty on the results of a statistical model.\n\n\nShow the code\nggplot(data = exam, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"blue\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                             group = RACE), \n              height = 0.6, \n              color = \"orange\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#installing-and-launching-r-packages-and-import-data",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#installing-and-launching-r-packages-and-import-data",
    "title": "Hands-on_Ex04",
    "section": "3.1 Installing and Launching R Packages and import data",
    "text": "3.1 Installing and Launching R Packages and import data\n\n\n\nPackages\nDescription\n\n\n\n\nreadr\nimporting csv into R\n\n\nFunnelPlotR\ncreate funnel plot\n\n\nggplot2\ncreating funnel plot manually\n\n\nknitr\nbuild static html table\n\n\nplotly\ncreating interactive funnel plot\n\n\n\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)\n\npackage 'plotly' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\carol\\AppData\\Local\\Temp\\Rtmp8UAGXw\\downloaded_packages\n\ncovid19 &lt;- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#funnelplotr-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#funnelplotr-methods",
    "title": "Hands-on_Ex04",
    "section": "3.2 FunnelPlotR methods",
    "text": "3.2 FunnelPlotR methods\nFunnel plots are particularly valuable in identifying publication bias, a phenomenon where studies reporting positive or statistically significant results are more likely to be published than studies with neutral or negative findings. Funnel plots visually depict the distribution of study effects, helping researchers detect asymmetry.\nFunnel plots can also reveal small-study effects, where smaller studies show more extreme results compared to larger studies. This can indicate potential biases in the selection or reporting of smaller studies.\n\n\nShow the code\nfunnel_plot(\n  numerator = covid19$Death,\n  denominator = covid19$Positive,\n  group = covid19$`Sub-district`,\n  data_type = \"PR\",   \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #&lt;&lt;           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #&lt;&lt;\n  y_label = \"Cumulative Fatality Rate\"  #&lt;&lt;\n)\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "title": "Hands-on_Ex04",
    "section": "3.3 Funnel Plot for Fair Visual Comparison: ggplot2 methods",
    "text": "3.3 Funnel Plot for Fair Visual Comparison: ggplot2 methods\nThe following code chunk enable to create funnel plot manually.\n\n\nShow the code\n#Computing the basic derived fields\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)\n\n#Calculate lower and upper limits for 95% and 99.9% CI\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)\n\n#Plotting a static funnel plot\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\n\n#Interactive Funnel Plot: plotly + ggplot2\nfp_ggplotly &lt;- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\n\n\nError in ggplotly(p, tooltip = c(\"label\", \"x\", \"y\")): could not find function \"ggplotly\"\n\n\nShow the code\nfp_ggplotly\n\n\nError in eval(expr, envir, enclos): object 'fp_ggplotly' not found\n\n\n\nIn summary, while ggplot2 is not inherently designed for funnel plots in the context of meta-analysis, it provides a powerful and flexible platform for creating custom visualizations, including funnel plots. The choice between the standard funnel plot methodology and ggplot2 would depend on the specific requirements of the analysis and the desired level of customization and flexibility."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on_Ex05",
    "section": "",
    "text": "Ternary plots are a way of displaying the distribution and variability of three-part compositional data. (For example, the proportion of aged, economy active and young population or sand, silt, and clay in soil.) It’s display is a triangle with sides scaled from 0 to 1. Each side represents one of the three components. A point is plotted so that a line drawn perpendicular from the point to each leg of the triangle intersect at the component values of the point.\n\n\n\nggtern, a ggplot extension specially designed to plot ternary diagrams. The package will be used to plot static ternary plots.\nPlotly R, an R package for creating interactive web-based graphs via plotly’s JavaScript graphing library, plotly.js . The plotly R libary contains the ggplotly function, which will convert ggplot2 figures into a Plotly object.\n\nWe will also need to ensure that selected tidyverse family packages namely: readr, dplyr and tidyr are also installed and loaded.\n\npacman::p_load(plotly, ggtern, tidyverse)\n\npackage 'plotly' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\carol\\AppData\\Local\\Temp\\RtmpSSw0Gq\\downloaded_packages\n\n\n\n\n\nTo important respopagsex2000to2018_tidy.csv into R, read_csv() function of readr package will be used. Next, use the mutate() function of dplyr package to derive three new measures, namely: young, active, and old.\n\n\nShow the code\n#Reading the data into R environment\npop_data &lt;- read_csv(\"data/respopagsex2000to2018_tidy.csv\") \n\n#Deriving the young, economy active and old measures\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate(`Year` = as.character(Year))%&gt;%\n  spread(AG, Population) %&gt;%\n  mutate(YOUNG = rowSums(.[4:8]))%&gt;%\n  mutate(ACTIVE = rowSums(.[9:16]))  %&gt;%\n  mutate(OLD = rowSums(.[17:21])) %&gt;%\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%\n  filter(Year == 2018)%&gt;%\n  filter(TOTAL &gt; 0)\n\n\n\n\n\n\n\nShow the code\n# reusable function for creating annotation object\nlabel &lt;- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n# reusable function for axis formatting\naxis &lt;- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes &lt;- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\n# Initiating a plotly visualization \nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %&gt;%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-launching-r-packages",
    "title": "Hands-on_Ex05",
    "section": "",
    "text": "ggtern, a ggplot extension specially designed to plot ternary diagrams. The package will be used to plot static ternary plots.\nPlotly R, an R package for creating interactive web-based graphs via plotly’s JavaScript graphing library, plotly.js . The plotly R libary contains the ggplotly function, which will convert ggplot2 figures into a Plotly object.\n\nWe will also need to ensure that selected tidyverse family packages namely: readr, dplyr and tidyr are also installed and loaded.\n\npacman::p_load(plotly, ggtern, tidyverse)\n\npackage 'plotly' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\carol\\AppData\\Local\\Temp\\RtmpSSw0Gq\\downloaded_packages"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#data-preparation",
    "title": "Hands-on_Ex05",
    "section": "",
    "text": "To important respopagsex2000to2018_tidy.csv into R, read_csv() function of readr package will be used. Next, use the mutate() function of dplyr package to derive three new measures, namely: young, active, and old.\n\n\nShow the code\n#Reading the data into R environment\npop_data &lt;- read_csv(\"data/respopagsex2000to2018_tidy.csv\") \n\n#Deriving the young, economy active and old measures\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate(`Year` = as.character(Year))%&gt;%\n  spread(AG, Population) %&gt;%\n  mutate(YOUNG = rowSums(.[4:8]))%&gt;%\n  mutate(ACTIVE = rowSums(.[9:16]))  %&gt;%\n  mutate(OLD = rowSums(.[17:21])) %&gt;%\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%\n  filter(Year == 2018)%&gt;%\n  filter(TOTAL &gt; 0)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-interative-ternary-diagram-with-r",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-interative-ternary-diagram-with-r",
    "title": "Hands-on_Ex05",
    "section": "",
    "text": "Show the code\n# reusable function for creating annotation object\nlabel &lt;- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n# reusable function for axis formatting\naxis &lt;- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes &lt;- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\n# Initiating a plotly visualization \nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %&gt;%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#overview",
    "title": "Hands-on_Ex05",
    "section": "2.1 Overview",
    "text": "2.1 Overview\nCorrelation coefficient is a popular statistic that use to measure the type and strength of the relationship between two variables. The values of a correlation coefficient ranges between -1.0 and 1.0. A correlation coefficient of 1 shows a perfect linear relationship between the two variables, while a -1.0 shows a perfect inverse relationship between the two variables. A correlation coefficient of 0.0 shows no linear relationship between the two variables.\nWhen multivariate data are used, the correlation coefficeints of the pair comparisons are displayed in a table form known as correlation matrix or scatterplot matrix.\nThere are three broad reasons for computing a correlation matrix.\n\nTo reveal the relationship between high-dimensional variables pair-wisely.\nTo input into other analyses. For example, people commonly use correlation matrices as inputs for exploratory factor analysis, confirmatory factor analysis, structural equation models, and linear regression when excluding missing values pairwise.\nAs a diagnostic when checking other analyses. For example, with linear regression a high amount of correlations suggests that the linear regression’s estimates will be unreliable.\n\nWhen the data is large, both in terms of the number of observations and the number of variables, Corrgram tend to be used to visually explore and analyse the structure and the patterns of relations among variables. It is designed based on two main schemes:\n\nRendering the value of a correlation to depict its sign and magnitude, and\nReordering the variables in a correlation matrix so that “similar” variables are positioned adjacently, facilitating perception."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-launching-r-packages-1",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-launching-r-packages-1",
    "title": "Hands-on_Ex05",
    "section": "2.2 Installing and Launching R Packages",
    "text": "2.2 Installing and Launching R Packages\nuse the code chunk below to install and launch corrplot, ggpubr, plotly and tidyverse in RStudio.\n\npacman::p_load(corrplot, ggstatsplot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-and-preparing-the-data-set",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-and-preparing-the-data-set",
    "title": "Hands-on_Ex05",
    "section": "2.3 Importing and Preparing The Data Set",
    "text": "2.3 Importing and Preparing The Data Set\nImport the data into R by using read_csv() of readr package.\n\nwine &lt;- read_csv(\"data/wine_quality.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#building-correlation-matrix-pairs-method",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#building-correlation-matrix-pairs-method",
    "title": "Hands-on_Ex05",
    "section": "2.4 Building Correlation Matrix: pairs() method",
    "text": "2.4 Building Correlation Matrix: pairs() method\nThere are more than one way to build scatterplot matrix with R. In this section, you will learn how to create a scatterplot matrix by using the pairs function of R Graphics. ### 2.4.1 Building a basic correlation matrix The numbers in the square bracket indicates the column number.\n\npairs(wine[,1:11])\n\n\n\n\n\n2.4.2 Drawing the lower corner\npairs function of R Graphics provided many customisation arguments. For example, it is a common practice to show either the upper half or lower half of the correlation matrix instead of both. This is because a correlation matrix is symmetric.\n\npairs(wine[,2:12], upper.panel = NULL)\n\n\n\n\n\n\n2.4.3 Including with correlation coefficients\nTo show the correlation coefficient of each pair of variables instead of a scatter plot, panel.cor function will be used. This will also show higher correlations in a larger font.\n\n\nShow the code\npanel.cor &lt;- function(x, y, digits=2, prefix=\"\", cex.cor, ...) {\nusr &lt;- par(\"usr\")\non.exit(par(usr))\npar(usr = c(0, 1, 0, 1))\nr &lt;- abs(cor(x, y, use=\"complete.obs\"))\ntxt &lt;- format(c(r, 0.123456789), digits=digits)[1]\ntxt &lt;- paste(prefix, txt, sep=\"\")\nif(missing(cex.cor)) cex.cor &lt;- 0.8/strwidth(txt)\ntext(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)\n}\n\npairs(wine[,2:12], \n      upper.panel = panel.cor)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-correlation-matrix-ggcormat",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-correlation-matrix-ggcormat",
    "title": "Hands-on_Ex05",
    "section": "2.5 Visualising Correlation Matrix: ggcormat()",
    "text": "2.5 Visualising Correlation Matrix: ggcormat()\nne of the major limitation of the correlation matrix is that the scatter plots appear very cluttered when the number of observations is relatively large (i.e. more than 500 observations). To over come this problem, Corrgram data visualisation technique suggested by D. J. Murdoch and E. D. Chow (1996) and Friendly, M (2002) and will be used.\n\n2.5.1 The basic plot\nOn of the advantage of using ggcorrmat() over many other methods to visualise a correlation matrix is it’s ability to provide a comprehensive and yet professional statistical report as shown in the figure below.\n\n\nShow the code\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11)\n\n\n\n\n\n2.5.2 Building multiple plots\nSince ggstasplot is an extension of ggplot2, it also supports faceting. However the feature is not available in ggcorrmat() but in the grouped_ggcorrmat() of ggstatsplot.\n\n\nShow the code\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 2),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-correlation-matrix-using-corrplot-package",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-correlation-matrix-using-corrplot-package",
    "title": "Hands-on_Ex05",
    "section": "2.6 Visualising Correlation Matrix using corrplot Package",
    "text": "2.6 Visualising Correlation Matrix using corrplot Package\n\n2.6.1 Basic corrplot\n\nwine.cor &lt;- cor(wine[, 1:11])\ncorrplot(wine.cor)\n\n\n\n\n\n\n2.6.2 Working with mixed layout\nWith corrplot package, it is possible to design corrgram with mixed visual matrix of one half and numerical matrix on the other half. In order to create a coorgram with mixed layout, the corrplot.mixed(), a wrapped function for mixed visualisation style will be used.\nFigure below shows a mixed layout corrgram plotted using wine quality data.\n\n\nShow the code\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n2.6.3 Combining corrgram with the significant test\nWith corrplot package, we can use the cor.mtest() to compute the p-values and confidence interval for each pair of variables.\n\n\nShow the code\nwine.sig = cor.mtest(wine.cor, conf.level= .95)\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05)\n\n\n\n\n\n\n\n2.6.4 Reordering a correlation matrix using hclust\nIf using hclust, corrplot() can draw rectangles around the corrgram based on the results of hierarchical clustering.\n\n\nShow the code\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order=\"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-and-preparing-the-data-set-1",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-and-preparing-the-data-set-1",
    "title": "Hands-on_Ex05",
    "section": "3.2 Importing and Preparing The Data Set",
    "text": "3.2 Importing and Preparing The Data Set\nIn the code chunk below, read_csv() of readr is used to import WHData-2018.csv into R and parsed it into tibble R data frame format.Change the rows by country name instead of row number by using the code chunk below\n\n\nShow the code\nwh &lt;- read_csv(\"data/WHData-2018.csv\")\nrow.names(wh) &lt;- wh$Country\nwh1 &lt;- dplyr::select(wh, c(3, 7:12))\nwh_matrix &lt;- data.matrix(wh)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#static-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#static-heatmap",
    "title": "Hands-on_Ex05",
    "section": "3.3 Static Heatmap",
    "text": "3.3 Static Heatmap\n\n3.3.1 heatmap() of R Stats\nTo plot a cluster heatmap, we just have to use the default as shown in the code chunk below.\n\n\nShow the code\nwh_heatmap &lt;- heatmap(wh_matrix)\n\n\n\n\n\nHere, red cells denotes small values, and red small ones. This heatmap is not really informative. Indeed, the Happiness Score variable have relatively higher values, what makes that the other variables with small values all look the same. Thus, we need to normalize this matrix. This is done using the scale argument. It can be applied to rows or to columns following your needs.\nThe code chunk below normalises the matrix column-wise.\n\n\nShow the code\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))\n\n\n\n\n\nNotice that the values are scaled now. Also note that margins argument is used to ensure that the entire x-axis labels are displayed completely and, cexRow and cexCol arguments are used to define the font size used for y-axis and x-axis labels respectively."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-interactive-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-interactive-heatmap",
    "title": "Hands-on_Ex05",
    "section": "3.4 Creating Interactive Heatmap",
    "text": "3.4 Creating Interactive Heatmap\nheatmaply is an R package for building interactive cluster heatmap that can be shared online as a stand-alone HTML file. It is designed and maintained by Tal Galili. ### 3.4.1 Working with heatmaply In this section, you will gain hands-on experience on using heatmaply to design an interactive cluster heatmap. We will still use the wh_matrix as the input data.\n\n\nShow the code\nheatmaply(mtcars)\n\n\n\n3.4.2 Seriation\nOne of the problems with hierarchical clustering is that it doesn’t actually place the rows in a definite order, it merely constrains the space of possible orderings. Take three items A, B and C. If you ignore reflections, there are three possible orderings: ABC, ACB, BAC. If clustering them gives you ((A+B)+C) as a tree, you know that C can’t end up between A and B, but it doesn’t tell you which way to flip the A+B cluster. It doesn’t tell you if the ABC ordering will lead to a clearer-looking heatmap than the BAC ordering.\nheatmaply uses the seriation package to find an optimal ordering of rows and columns. Optimal means to optimize the Hamiltonian path length that is restricted by the dendrogram structure. This, in other words, means to rotate the branches so that the sum of distances between each adjacent leaf (label) will be minimized. This is related to a restricted version of the travelling salesman problem.\nHere we meet our first seriation algorithm: Optimal Leaf Ordering (OLO). This algorithm starts with the output of an agglomerative clustering algorithm and produces a unique ordering, one that flips the various branches of the dendrogram around so as to minimize the sum of dissimilarities between adjacent leaves. Here is the result of applying Optimal Leaf Ordering to the same clustering result as the heatmap above.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\nError in heatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]), seriate = \"OLO\"): could not find function \"heatmaply\"\n\n\nThe option “mean” gives the output we would get by default from heatmap functions in other packages such as gplots::heatmap.2.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"mean\")\n\nError in heatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]), seriate = \"mean\"): could not find function \"heatmaply\"\n\n\n\n\n3.4.3 Working with colour palettes\nThe default colour palette uses by heatmaply is viridis. heatmaply users, however, can use other colour palettes in order to improve the aestheticness and visual friendliness of the heatmap.\nIn the code chunk below, the Blues colour palette of rColorBrewer is used\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\",\n          colors = Blues)\n\nError in heatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]), seriate = \"none\", : could not find function \"heatmaply\"\n\n\n\n\n3.4.4 The finishing touch\nBeside providing a wide collection of arguments for meeting the statistical analysis needs, heatmaply also provides many plotting features to ensure cartographic quality heatmap can be produced.\nIn the code chunk below the following arguments are used:\n\nk_row is used to produce 5 groups.\nmargins is used to change the top margin to 60 and row margin to 200.\nfontsizw_row and fontsize_col are used to change the font size for row and column labels to 4.\nmain is used to write the main title of the plot.\nxlab and ylab are used to write the x-axis and y-axis labels respectively.\n\n\n\nShow the code\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )\n\n\nError in heatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]), Colv = NA, : could not find function \"heatmaply\""
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-launching-r-packages-and-data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-launching-r-packages-and-data-preparation",
    "title": "Hands-on_Ex05",
    "section": "4.1 Installing, Launching R Packages and Data Preparation",
    "text": "4.1 Installing, Launching R Packages and Data Preparation\n\npacman::p_load(GGally, parallelPlot, tidyverse)\n\npackage 'parallelPlot' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\carol\\AppData\\Local\\Temp\\RtmpSSw0Gq\\downloaded_packages\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-static-parallel-coordinates-plot",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-static-parallel-coordinates-plot",
    "title": "Hands-on_Ex05",
    "section": "4.2 Plotting Static Parallel Coordinates Plot",
    "text": "4.2 Plotting Static Parallel Coordinates Plot\nplot static parallel coordinates plot by using ggparcoord() of GGally package. Before getting started, it is a good practice to read the function description in detail.\n\n4.2.1 Plotting a simple parallel coordinates\nCode chunk below shows a typical syntax used to plot a basic static parallel coordinates plot by using ggparcoord().\n\n\nShow the code\nggparcoord(data = wh, \n           columns = c(7:12))\n\n\n\n\n\n\n\n4.2.2 Plotting a parallel coordinates with boxplot\nThe basic parallel coordinates failed to reveal any meaning understanding of the World Happiness measures. In this section, you will learn how to makeover the plot by using a collection of arguments provided by ggparcoord().\n\n\nShow the code\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\")\n\n\n\n\n\n\n\n4.2.3 Parallel coordinates with facet\nSince ggparcoord() is developed by extending ggplot2 package, we can combination use some of the ggplot2 function when plotting a parallel coordinates plot.\nIn the code chunk below, facet_wrap() of ggplot2 is used to plot 10 small multiple parallel coordinates plots. Each plot represent one geographical region such as East Asia.\n\n\nShow the code\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30, hjust=1))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "title": "Hands-on_Ex05",
    "section": "4.3 Plotting Interactive Parallel Coordinates Plot: parallelPlot methods",
    "text": "4.3 Plotting Interactive Parallel Coordinates Plot: parallelPlot methods\nparallelPlot is an R package specially designed to plot a parallel coordinates plot by using ‘htmlwidgets’ package and d3.js. In this section, you will learn how to use functions provided in parallelPlot package to build interactive parallel coordinates plot.\n\n\nShow the code\nhistoVisibility &lt;- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)\n\n\nError in parallelPlot(wh, rotateTitle = TRUE, histoVisibility = histoVisibility): could not find function \"parallelPlot\""
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-launching-r-packages-2",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-launching-r-packages-2",
    "title": "Hands-on_Ex05",
    "section": "5.1 Installing and Launching R Packages",
    "text": "5.1 Installing and Launching R Packages\nCheck if treemap and tidyverse pacakges have been installed\n\npacman::p_load(treemap, treemapify, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#data-preparation-1",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#data-preparation-1",
    "title": "Hands-on_Ex05",
    "section": "5.2 Data Preparation",
    "text": "5.2 Data Preparation\nThe data.frame realis2018 is in trasaction record form, which is highly disaggregated and not appropriate to be used to plot a treemap. In this section, we will perform the following steps to manipulate and prepare a data.frtame that is appropriate for treemap visualisation:\n\ngroup transaction records by Project Name, Planning Region, Planning Area, Property Type and Type of Sale, and\ncompute Total Unit Sold, Total Area, Median Unit Price and Median Transacted Price by applying appropriate summary statistics on No. of Units, Area (sqm), Unit Price ($ psm) and Transacted Price ($) respectively.\n\nTwo key verbs of dplyr package, namely: group_by() and summarize() will be used to perform these steps.\ngroup_by() breaks down a data.frame into specified groups of rows. When you then apply the verbs above on the resulting object they’ll be automatically applied “by group”.\n\n\nShow the code\nrealis2018 &lt;- read_csv(\"data/realis2018.csv\")\n\nrealis2018_grouped &lt;- group_by(realis2018, `Project Name`,\n                               `Planning Region`, `Planning Area`, \n                               `Property Type`, `Type of Sale`)\nrealis2018_summarised &lt;- summarise(realis2018_grouped, \n                          `Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE),\n                          `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n                          `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE), \n                          `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\nrealis2018_summarised &lt;- realis2018 %&gt;% \n  group_by(`Project Name`,`Planning Region`, \n           `Planning Area`, `Property Type`, \n           `Type of Sale`) %&gt;%\n  summarise(`Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE), \n            `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n            `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE),\n            `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#designing-treemap-with-treemap-package",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#designing-treemap-with-treemap-package",
    "title": "Hands-on_Ex05",
    "section": "5.3 Designing Treemap with treemap Package",
    "text": "5.3 Designing Treemap with treemap Package\ntreemap package is a R package specially designed to offer great flexibility in drawing treemaps. The core function, namely: treemap() offers at least 43 arguments. In this section, we will only explore the major arguments for designing elegent and yet truthful treemaps.\n\n5.3.1 Designing a static treemap\nThe code chunk below designed a treemap by using three core arguments of treemap(), namely: index, vSize and vColor.\n\n\nShow the code\nrealis2018_selected &lt;- realis2018_summarised %&gt;%\n  filter(`Property Type` == \"Condominium\", `Type of Sale` == \"Resale\")\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\nThings to learn from the three arguments used:\nindex\n\nThe index vector must consist of at least two column names or else no hierarchy treemap will be plotted.\nIf multiple column names are provided, such as the code chunk above, the first name is the highest aggregation level, the second name the second highest aggregation level, and so on.\n\nvSize\n\nThe column must not contain negative values. This is because it’s vaues will be used to map the sizes of the rectangles of the treemaps.\n\n\n\n5.3.2 Working with vColor and type arguments\nn the code chunk below, type argument is define as value.\n\n\nShow the code\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type = \"value\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n5.3.3 Working with algorithm argument and using sortID\nThe code chunk below plots a squarified treemap by changing the algorithm argument. When “pivotSize” algorithm is used, sortID argument can be used to dertemine the order in which the rectangles are placed from top left to bottom right.\n\n\nShow the code\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"pivotSize\",\n        sortID = \"Median Transacted Price\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#designing-treemap-using-treemapify-package",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#designing-treemap-using-treemapify-package",
    "title": "Hands-on_Ex05",
    "section": "5.4 Designing Treemap using treemapify Package",
    "text": "5.4 Designing Treemap using treemapify Package\ntreemapify is a R package specially developed to draw treemaps in ggplot2. In this section, you will learn how to designing treemps closely resemble treemaps designing in previous section by using treemapify. Before you getting started, you should read Introduction to “treemapify” its user guide.\n\n5.4.1 Designing a basic treemap\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`),\n       layout = \"scol\",\n       start = \"bottomleft\") + \n  geom_treemap() +\n  scale_fill_gradient(low = \"light blue\", high = \"pink\")\n\n\n\n\n\n\n5.4.2 Defining hierarchy\nGroup by Planning Region\n\n\nShow the code\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`),\n       start = \"topleft\") + \n  geom_treemap()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#designing-interactive-treemap-using-d3treer",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#designing-interactive-treemap-using-d3treer",
    "title": "Hands-on_Ex05",
    "section": "5.5 Designing Interactive Treemap using d3treeR",
    "text": "5.5 Designing Interactive Treemap using d3treeR\n\n5.5.1 Installing d3treeR package\n\ninstall.packages(\"devtools\")\n\npackage 'devtools' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\carol\\AppData\\Local\\Temp\\RtmpSSw0Gq\\downloaded_packages\n\nlibrary(devtools)\n\nError: package or namespace load failed for 'devtools' in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]):\n namespace 'htmltools' 0.5.6 is already loaded, but &gt;= 0.5.7 is required\n\ninstall_github(\"timelyportfolio/d3treeR\")\n\nError in install_github(\"timelyportfolio/d3treeR\"): could not find function \"install_github\"\n\nlibrary(d3treeR)\n\n\n\n5.5.2 Designing An Interactive Treemap\nThe codes below perform two processes.\n\ntreemap() is used to build a treemap by using selected variables in condominium data.frame. The treemap created is save as object called tm.\nThen d3tree() is used to build an interactive treemap.\n\n\n\nShow the code\ntm &lt;- treemap(realis2018_summarised,\n        index=c(\"Planning Region\", \"Planning Area\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        title=\"Private Residential Property Sold, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\nd3tree(tm,rootname = \"Singapore\" )\n\nError in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]): namespace 'htmltools' 0.5.6 is already loaded, but &gt;= 0.5.7 is required"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "title": "In-class_Ex02",
    "section": "",
    "text": "Link to Tableau public"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take-home_Ex02",
    "section": "",
    "text": "In this take home exercise, we aim to provide critique and improvements based on the plots and analysis created by peers. It will be done based on clarity and aesthetics.\nThe focus of this exercise will be data preparation critique, data visualization critique and conclusion presentation critique."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#students-performance-distribution-by-gender",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#students-performance-distribution-by-gender",
    "title": "Take-home_Ex02",
    "section": "3.1 Students Performance Distribution by Gender",
    "text": "3.1 Students Performance Distribution by Gender\n\n3.1.1 Original Design\nThe plots below shows the original design of the distribution of Singapore student performance by gender.\n\n\n\n\n\n\n\n\n\nClarity\nAesthetics\n\n\n\n\n\nUtilizes 2x2 histogram and 2x2 density plot for visualizing score distribution by gender.\nDifferentiates plot elements with distinct colors, enhancing clarity.\nBoth plots effectively display skewness and distribution shape.\n\n\nConsistent and distinguishable color palette used for both histogram and density plot.\nBackground maintains consistency with soft grid lines, minimizing distraction.\nClear legend and labels contribute to overall aesthetic appeal.\n\n\n\n\n\n\n\n\n\n\nLimitation\n\n\n\n\n\nDoes not depict mean, median, or average score for each subject.\nHistogram, using count as the y-axis, results in a lower distribution for “Male,” affecting comparability between genders.\n\n\n\n\n\n\n3.1.2 Makeover Design - Violin-plot with Box-plot\nIt can be further developed by plotting a 2x2 violin plot combine with boxplot with a red dot representing the mean, which shall present the data distribution especially the quantile more clearly.\n\n\nShow the code\np1 &lt;- ggplot(PV_Avg_gender, aes(x = as.factor(gender), y = Avg_PVMath, fill = as.factor(gender))) +\n  geom_violin() +\n  geom_boxplot(width = 0.2, position = position_dodge(width = 0.75)) +\n  stat_summary(\n    fun = median,\n    geom = \"text\",\n    aes(label = round(after_stat(y), )),\n    position = position_dodge(width = 0.75),\n    vjust = -1,\n    size = 3,\n    color = \"black\"\n  ) +\n  stat_summary(\n    fun = mean,\n    geom = \"text\",\n    aes(label = round(after_stat(y), )),\n    position = position_dodge(width = 0.75),\n    vjust = 1.5,\n    size = 3,\n    color = \"#B00000\"\n  ) +\n   # Add geom_text layer for displaying mean dot in red\n  stat_summary(fun = mean, geom = \"point\", shape = 16, size = 3, color = \"#B00000\",\n               position = position_nudge(x = 0.0))+\n  labs(title = \"Violin Plot of PV Math Scores by Gender\",\n       x = \"Gender\",\n       y = \"Average PV Math Score\") +\n  scale_fill_manual(values = c(\"khaki3\",\"slategray3\"), name = \"Gender\",\n                    labels = c(\"1\" = \"Female\", \"2\" = \"Male\"))+\n  scale_x_discrete(labels = c(\"1\" = \"Female\", \"2\" = \"Male\")) +\n  theme_minimal()+\n    theme(\n      text = element_text(size = 8),  # Set the general text size\n      plot.title = element_text(size = 10),  # Set the title size\n      plot.subtitle = element_text(size = 8)  # Set the subtitle size\n    )\n\np2 &lt;- ggplot(PV_Avg_gender, aes(x = as.factor(gender), y = Avg_PVRead, fill = as.factor(gender))) +\n  geom_violin() +\n  geom_boxplot(width = 0.2, position = position_dodge(width = 0.75)) +\n  stat_summary(\n    fun = median,\n    geom = \"text\",\n    aes(label = round(after_stat(y), )),\n    position = position_dodge(width = 0.75),\n    vjust = -1,\n    size = 3,\n    color = \"black\"\n  ) +\n  stat_summary(\n    fun = mean,\n    geom = \"text\",\n    aes(label = round(after_stat(y), )),\n    position = position_dodge(width = 0.75),\n    vjust = 1.5,\n    size = 3,\n    color = \"#B00000\"\n  ) +\n   # Add geom_text layer for displaying mean dot in red\n  stat_summary(fun = mean, geom = \"point\", shape = 16, size = 3, color = \"#B00000\",\n               position = position_nudge(x = 0.0))+\n  labs(title = \"Violin Plot of PV Reading Scores by Gender\",\n       x = \"Gender\",\n       y = \"Average PV Reading Score\") +\n  scale_fill_manual(values = c(\"khaki3\",\"slategray3\"), name = \"Gender\",\n                    labels = c(\"1\" = \"Female\", \"2\" = \"Male\"))+\n  scale_x_discrete(labels = c(\"1\" = \"Female\", \"2\" = \"Male\")) +\n  theme_minimal()+\n    theme(\n      text = element_text(size = 8),  # Set the general text size\n      plot.title = element_text(size = 10),  # Set the title size\n      plot.subtitle = element_text(size = 8)  # Set the subtitle size\n    )\n\np3 &lt;- ggplot(PV_Avg_gender, aes(x = as.factor(gender), y = Avg_PVScience, fill = as.factor(gender))) +\n  geom_violin() +\n  geom_boxplot(width = 0.2, position = position_dodge(width = 0.75)) +\n  stat_summary(\n    fun = median,\n    geom = \"text\",\n    aes(label = round(after_stat(y), )),\n    position = position_dodge(width = 0.75),\n    vjust = -1,\n    size = 3,\n    color = \"black\"\n  ) +\n  stat_summary(\n    fun = mean,\n    geom = \"text\",\n    aes(label = round(after_stat(y), )),\n    position = position_dodge(width = 0.75),\n    vjust = 1.5,\n    size = 3,\n    color = \"#B00000\"\n  ) +\n   # Add geom_text layer for displaying mean dot in red\n  stat_summary(fun = mean, geom = \"point\", shape = 16, size = 3, color = \"#B00000\",\n               position = position_nudge(x = 0.0))+\n  labs(title = \"Violin Plot of PV Science Scores by Gender\",\n       x = \"Gender\",\n       y = \"Average PV Science Score\") +\n  scale_fill_manual(values = c(\"khaki3\",\"slategray3\"), name = \"Gender\",\n                    labels = c(\"1\" = \"Female\", \"2\" = \"Male\"))+\n  scale_x_discrete(labels = c(\"1\" = \"Female\", \"2\" = \"Male\")) +\n  theme_minimal()+\n    theme(\n      text = element_text(size = 8),  # Set the general text size\n      plot.title = element_text(size = 10),  # Set the title size\n      plot.subtitle = element_text(size = 8)  # Set the subtitle size\n    )\n\np4 &lt;- ggplot(PV_Avg_gender, aes(x = as.factor(gender), y = ((Avg_PVMath+Avg_PVRead+Avg_PVScience)/3), fill = as.factor(gender))) +\n  geom_violin() +\n  geom_boxplot(width = 0.2, position = position_dodge(width = 0.75)) +\n  stat_summary(\n    fun = median,\n    geom = \"text\",\n    aes(label = round(after_stat(y), )),\n    position = position_dodge(width = 0.75),\n    vjust = -1,\n    size = 3,\n    color = \"black\"\n  ) +\n  stat_summary(\n    fun = mean,\n    geom = \"text\",\n    aes(label = round(after_stat(y), )),\n    position = position_dodge(width = 0.75),\n    vjust = 1.5,\n    size = 3,\n    color = \"#B00000\"\n  ) +\n   # Add geom_text layer for displaying mean dot in red\n  stat_summary(fun = mean, geom = \"point\", shape = 16, size = 3, color = \"#B00000\",\n               position = position_nudge(x = 0.0))+\n  labs(title = \"Violin Plot of PV Average Scores by Gender\",\n       x = \"Gender\",\n       y = \"Average PV Average Score\") +\n  scale_fill_manual(values = c(\"khaki3\",\"slategray3\"), name = \"Gender\",\n                    labels = c(\"1\" = \"Female\", \"2\" = \"Male\"))+\n  scale_x_discrete(labels = c(\"1\" = \"Female\", \"2\" = \"Male\")) +\n  theme_minimal()+\n    theme(\n      text = element_text(size = 8),  # Set the general text size\n      plot.title = element_text(size = 10),  # Set the title size\n      plot.subtitle = element_text(size = 8)  # Set the subtitle size\n    )\n\np1+p2+p3+p4\n\n\n\nImprovements:\n\nEnhanced Distribution Comparison:\n\nViolin plots combine aspects of boxplots and kernel density plots, providing a more comprehensive view of the data distribution.\nThe width of the violin plot represents the density of scores, making it easier to compare distributions between genders.\nThe presentation of grid lines enhance the clarity of presentation.\n\nBoxplot Insights:\n\nBoxplots within the violin plot offer insights into the quartiles, median, and potential outliers, providing a summary of central tendency and spread. For example, we can observe that generally male students have a wider performance spread.\nBoxplots are effective in highlighting any gender-based differences in terms of median and spread. From the box plot with red dot representing mean score, we can conclude that the average performance of female and male are close. Female students have higher mean and median in Reading, male students have better performance in Math and Science.\n\nOutlier Detection:\n\nThe combination of violin and boxplots facilitates easy identification of outliers in each gender category. It can be observed that for each sub-plot, there are outliers at the lower end.\nOutliers can be crucial in understanding extreme scores and potential factors influencing them."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#students-performance-distribution-by-school",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#students-performance-distribution-by-school",
    "title": "Take-home_Ex02",
    "section": "3.2 Students performance Distribution by School",
    "text": "3.2 Students performance Distribution by School\n\n3.2.1 Original Design\nThe following plots are the original design. Violin plot with box-plot and labeled the top 3 schools and bottom 2 schools.\n\n\n\n\n\n\n\n\nClarity\nAesthetics\n\n\n\n\n\nExcellent clarity in the violin plot combined with the box plot.\nBoxplots within the violin plot provide insights into quartiles, median, and potential outliers.\nSummary of central tendency and spread is effectively communicated.\n\n\nColors are visually appealing and facilitate easy distinction between subjects.\nClean background enhances the overall aesthetic appeal.\nClear legend and labels contribute to the visual appeal.\nLabels for top 3 and bottom 2 schools are positioned to avoid overlapping.\n\n\n\n\n\n\n\n\n\n\nPossible Improvements\n\n\n\n\n\nThe current plot is nearly perfect.\nSuggestion to enhance the analysis by exploring further details of the top 3 and bottom 2 schools.\nAddition of a density plot for a more in-depth examination.\nConsider incorporating grid lines to improve reference and readability in the plot.\n\n\n\n\n\n\n3.2.2 Makeover Design - Density plot of Top 3 and Bottom 2 Schools\nThe following is the proposed density plot of top 3 schools and bottom 2 schools.\n\n\nShow the code\n# Filter data for top 3 and bottom 2 schools\ntop_schools &lt;- stu_df[stu_df$School_ID %in% c(70200003, 70200001, 70200101), ]\nbottom_schools &lt;- stu_df[stu_df$School_ID %in% c(70200115, 70200149), ]\n\n# Create density plots\nggplot() +\n  geom_density(data = top_schools, aes(x = Average_Score, fill = as.factor(School_ID)), alpha = 0.5) +\n  geom_density(data = bottom_schools, aes(x = Average_Score, fill = as.factor(School_ID)), alpha = 0.5) +\n  labs(title = \"Density Plot of Top 3 and Bottom 2 Schools\",\n       x = \"Average Score\",\n       y = \"Density\",\n       fill = \"School ID\") +\n  scale_fill_manual(values = c(\"#FF69B4\", \"#6495ED\", \"#32CD32\", \"#FFD700\", \"#FF4500\")) +\n  theme_minimal()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#students-performance-distribution-by-home-possessions",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#students-performance-distribution-by-home-possessions",
    "title": "Take-home_Ex02",
    "section": "3.3 Students Performance Distribution by Home Possessions",
    "text": "3.3 Students Performance Distribution by Home Possessions\n\n3.3.1 Original design\nThe initial plot is clear and visually appealing. The only potential improvement that comes to mind is the red line running through the midpoint of each box plot’s median. However, the line appears jagged, making it challenging to discern the pattern and trend in the relationship between score and the number of home possessions.\n\n\nShow the code\nggplot(data = PV_Avg_HOMEPOS, aes(x = factor(Home_Possessions), y = Avg_PVOverall)) +\n  geom_boxplot(width = 0.5, fill = \"#D2B4E8\") +\n  stat_summary(fun = \"median\", geom = \"line\", aes(group = 1), color = \"red\", linewidth = 1) +  \n  labs(x = \"HOMEPOS\", y = \"Overall Score\", title = \"Distribution of Overall Scores by HOMEPOS\") +\n  theme_classic()\n\n\n\n\n\n3.3.2 Makeover\nThis code chunk includes a smoothing line (geom_smooth) using the loess method, providing a visual representation of the trend in the relationship between HOMEPOS and Average_Score. This can be useful for identifying overall patterns and trends in the data.\n\n\nShow the code\npos_df &lt;- data.frame(\n  HOMEPOS = rowSums(stu_df[, c(\"Possession_book\", \"Possession_internet\", \"Possession_phone\", \n                                \"Possession_software\", \"Possession_computer\", \"Possession_room\")]),\n  Average_Score = stu_df$Average_Score\n)\n\nggplot(data = na.omit(pos_df), aes(x = factor(HOMEPOS), y = Average_Score)) +\n  geom_boxplot(fill = \"lightblue\", outlier.shape = NA) +\n  geom_smooth(aes(group = 1), method = \"loess\", se = FALSE, color = \"red\", size = 1) +\n  labs(x = \"HOMEPOS (Binned)\", y = \"Average Score\", title = \"Relationship between HOMEPOS and Average Score\") +\n  theme_minimal()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/Hands-on_Ex06.html",
    "href": "In-class_Ex/In-class_Ex06/Hands-on_Ex06.html",
    "title": "Horizon Plot",
    "section": "",
    "text": "pacman::p_load(ggHoriPlot, ggthemes, tidyverse) \n\n\naverp&lt;- read.csv(\"data/AVERP.csv\")%&gt;%\n  mutate(`Date` = dmy(`Date`))\n\n\n# | fig-width: 12\n# | fig-height: 10\naverp %&gt;% \n  filter(Date &gt;= \"2018-01-01\") %&gt;%\n  ggplot() +\n  geom_horizon(aes(x = Date, y=Values), \n               origin = \"midpoint\", \n               horizonscale = 6)+\n  facet_grid(`Consumer.Items`~.) +\n    theme_few() +\n  scale_fill_hcl(palette = 'RdBu') +\n  theme(panel.spacing.y=unit(0, \"lines\"), strip.text.y = element_text(\n    size = 5, angle = 0, hjust = 0),\n    legend.position = 'none',\n    axis.text.y = element_blank(),\n    axis.text.x = element_text(size=7),\n    axis.title.y = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.border = element_blank()\n    ) +\n    scale_x_date(expand=c(0,0), date_breaks = \"3 month\", date_labels = \"%b%y\") +\n  ggtitle('Average Retail Prices of Selected Consumer Items (Jan 2018 to Dec 2022)')\n\nWarning: Using the `size` aesthetic in this geom was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` in the `default_aes` field and elsewhere instead."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-on_Ex06",
    "section": "",
    "text": "By the end of this hands-on exercise you will be able create the followings data visualisation by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a slopegraph\nplotting a horizon chart"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#load-packages",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#load-packages",
    "title": "Hands-on_Ex06",
    "section": "2.1 Load packages",
    "text": "2.1 Load packages\nInstall and launch the following R packages: scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table and tidyverse.\n\npacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table, CGPfunctions, ggHoriPlot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#import-data",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#import-data",
    "title": "Hands-on_Ex06",
    "section": "2.2 Import data",
    "text": "2.2 Import data\nInstall and launch the following R packages: scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table and tidyverse.\n\nattacks &lt;- read_csv(\"data/eventlog.csv\")\n\nRows: 199999 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): source_country, tz\ndttm (1): timestamp\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#examine-data-structure",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#examine-data-structure",
    "title": "Hands-on_Ex06",
    "section": "2.3 Examine Data Structure",
    "text": "2.3 Examine Data Structure\nkable() can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\ntz field stores time zone of the source IP address."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#data-preparation",
    "title": "Hands-on_Ex06",
    "section": "2.4 Data Preparation",
    "text": "2.4 Data Preparation\nStep 1: Deriving weekday and hour of day fields\n\n\nShow the code\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\n\nStep 2: Deriving the attacks tibble data frame\n\n\nShow the code\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\n\nTable below shows the tidy tibble table after processing.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#building-the-calendar-heatmaps",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#building-the-calendar-heatmaps",
    "title": "Hands-on_Ex06",
    "section": "3.1 Building the Calendar Heatmaps",
    "text": "3.1 Building the Calendar Heatmaps\n\n\nShow the code\ngrouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-multiple-calendar-heatmaps",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-multiple-calendar-heatmaps",
    "title": "Hands-on_Ex06",
    "section": "3.2 Plotting Multiple Calendar Heatmaps",
    "text": "3.2 Plotting Multiple Calendar Heatmaps\n\n\nShow the code\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )\n\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#data-preparation-1",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#data-preparation-1",
    "title": "Hands-on_Ex06",
    "section": "4.1 Data Preparation",
    "text": "4.1 Data Preparation\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\n\nShow the code\nair &lt;- read_excel(\"data/arrivals_by_air.xlsx\")\n\nair$month &lt;- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year &lt;- year(ymd(air$`Month-Year`))\n\nVietnam &lt;- air %&gt;% \n  select(`Vietnam`, \n         month, \n         year) %&gt;%\n  filter(year &gt;= 2010)\n\nhline.data &lt;- Vietnam %&gt;% \n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-the-cycle-plot",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-the-cycle-plot",
    "title": "Hands-on_Ex06",
    "section": "4.2 Plotting the cycle plot",
    "text": "4.2 Plotting the cycle plot\nThe code chunk below is used to plot the cycle plot as shown in Slide 12/23.\n\n\nShow the code\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  theme_tufte(base_family = \"Helvetica\")\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\nnot found in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database\n\n\nWarning in grid.Call.graphics(C_text, as.graphicsAnnot(x$label), x$x, x$y, :\nfont family not found in Windows font database\n\n\nWarning in grid.Call(C_textBounds, as.graphicsAnnot(x$label), x$x, x$y, : font\nfamily not found in Windows font database"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#data-preparation-2",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#data-preparation-2",
    "title": "Hands-on_Ex06",
    "section": "5.1 Data Preparation",
    "text": "5.1 Data Preparation\nImport the rice data set into R environment by using the code chunk below.\n\nrice &lt;- read_csv(\"data/rice.csv\")\n\nRows: 550 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Country\ndbl (3): Year, Yield, Production\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-the-slopegraph",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-the-slopegraph",
    "title": "Hands-on_Ex06",
    "section": "5.2 Plotting the slopegraph",
    "text": "5.2 Plotting the slopegraph\nNext, code chunk below will be used to plot a basic slopegraph as shown below.\n\n\nShow the code\nrice %&gt;% \n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Counties\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Prepared by: Dr. Kam Tin Seong\")\n\n\n\nConverting 'Year' to an ordered factor"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "title": "Horizon Plot",
    "section": "",
    "text": "pacman::p_load(ggHoriPlot, ggthemes, tidyverse) \n\n\naverp&lt;- read.csv(\"data/AVERP.csv\")%&gt;%\n  mutate(`Date` = dmy(`Date`))\n\n\n# | fig-width: 12\n# | fig-height: 10\naverp %&gt;% \n  filter(Date &gt;= \"2018-01-01\") %&gt;%\n  ggplot() +\n  geom_horizon(aes(x = Date, y=Values), \n               origin = \"midpoint\", \n               horizonscale = 6)+\n  facet_grid(`Consumer.Items`~.) +\n    theme_few() +\n  scale_fill_hcl(palette = 'RdBu') +\n  theme(panel.spacing.y=unit(0, \"lines\"), strip.text.y = element_text(\n    size = 5, angle = 0, hjust = 0),\n    legend.position = 'none',\n    axis.text.y = element_blank(),\n    axis.text.x = element_text(size=7),\n    axis.title.y = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.border = element_blank()\n    ) +\n    scale_x_date(expand=c(0,0), date_breaks = \"3 month\", date_labels = \"%b%y\") +\n  ggtitle('Average Retail Prices of Selected Consumer Items (Jan 2018 to Dec 2022)')\n\nWarning: Using the `size` aesthetic in this geom was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` in the `default_aes` field and elsewhere instead."
  }
]